{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "def wavPlayer(filepath):\n",
    "    \"\"\" will display html 5 player for compatible browser\n",
    "\n",
    "    Parameters :\n",
    "    ------------\n",
    "    filepath : relative filepath with respect to the notebook directory ( where the .ipynb are not cwd)\n",
    "               of the file to play\n",
    "\n",
    "    The browser need to know how to play wav through html5.\n",
    "\n",
    "    there is no autoplay to prevent file playing when the browser opens\n",
    "    \"\"\"\n",
    "    \n",
    "    src = \"\"\"\n",
    "    <head>\n",
    "    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
    "    <title>Simple Test</title>\n",
    "    </head>\n",
    "    \n",
    "    <body>\n",
    "    <audio controls=\"controls\" style=\"width:600px\" >\n",
    "      <source src=\"files/%s\" type=\"audio/wav\" />\n",
    "      Your browser does not support the audio element.\n",
    "    </audio>\n",
    "    </body>\n",
    "    \"\"\"%(filepath)\n",
    "    display(HTML(src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "s_dict = {'table_start': 0, 'hand_start': 1, 'off_start': 2}\n",
    "fi_dict = {'nothing': 0, 'pasta': 1, 'rice': 2, 'water': 3}\n",
    "fu_dict = {'zero': 0, 'fifty': 1, 'ninety': 2}\n",
    "b_dict = {'regular': 0, 'textured': 1}\n",
    "l_dict = {'light0': 0, 'light1': 1}\n",
    "c_dict = {'c1': 1, 'c2': 2, 'c3': 3, 'c4': 4}\n",
    "obj_id_dict = {1: 'red cup', 2: 'small white cup',3:'small transparent cup',4:'green glass',5:'wine glass',\n",
    "              6:'champagne flute glass', 7:'cereal box',8:'biscuit box',9:'tea box', 10: 'sth', 11: 'sth2', 12: 'sth3'} \n",
    "\n",
    "valid_dict = {'s': list(s_dict.keys()), \n",
    "              'fi': list(fi_dict.keys()),\n",
    "              'fu': list(fu_dict.keys()),\n",
    "              'b': list(b_dict.keys()),\n",
    "              'l': list(l_dict.keys()),\n",
    "              'c': list(c_dict.keys()),\n",
    "              'obj_id': list(obj_id_dict.keys()),\n",
    "             }\n",
    "\n",
    "def retrieve_data(obj_id, s, fi, fu, b, l, c=[]):\n",
    "    if ((fi == 'nothing' and (fu =='fifty' or fu =='ninety')) or (fi == 'pasta' and fu == 'zero') or (fi == 'rice' and fu=='zero') or (fi=='water' and fu=='zero')): \n",
    "        #print('error')\n",
    "        return -1\n",
    "    for i in range(1,len(c),1):\n",
    "        if c[i] not in valid_dict['c']:\n",
    "            return -1\n",
    "    if  (obj_id not in obj_id_dict) or (s not in valid_dict['s']) or (fi not in valid_dict['fi']) or (fu not in valid_dict['fu']) or (b not in valid_dict['b']) or (l not in valid_dict['l']) :\n",
    "        return -1\n",
    "    \n",
    "    _obj_id = obj_id\n",
    "    _s_id = s_dict[s]\n",
    "    _fi_id = fi_dict[fi]\n",
    "    _fu_id = fu_dict[fu]\n",
    "    _b_id = b_dict[b]\n",
    "    _l_id = l_dict[l]\n",
    "    _c_id = []\n",
    "    \n",
    "    for i in range(0,len(c),1):\n",
    "        _c_id.append(c_dict[c[i]])\n",
    "    if(len(c)==0):\n",
    "        _c_id = [1,2,3,4]\n",
    "        \n",
    "    input_string = 's'+str(_s_id)+'_fi'+str(_fi_id)+'_fu'+str(_fu_id)+'_b'+str(_b_id)+'_l'+str(_l_id)\n",
    "    \n",
    "    audio_path = \"./*Dataset/\"+str(_obj_id)+\"/audio/\"+input_string+\"*\"\n",
    "    audio_list = glob.glob(audio_path)[0]\n",
    "    \n",
    "    calib_list = []\n",
    "    for i in range(0,len(_c_id),1):\n",
    "        calib_path = \"./*Dataset/\"+str(_obj_id)+\"/calib/\"+input_string+'_c'+str(_c_id[i])+'*'\n",
    "        calib_list.append(glob.glob(calib_path)[0])\n",
    "    \n",
    "    depth_list = []\n",
    "    for i in range(0,len(_c_id),1):\n",
    "        depth_path = \"./*Dataset/\"+str(_obj_id)+\"/depth/\"+input_string+'/c'+str(_c_id[i])+'/*'\n",
    "        depth_list.append(glob.glob(depth_path))\n",
    "        \n",
    "    imu_path = \"./*Dataset/\"+str(_obj_id)+\"/imu/\"+input_string+\"*\"\n",
    "    imu_list = tuple(glob.glob(imu_path))\n",
    "    \n",
    "    \n",
    "    ir_list=[]\n",
    "    for i in range(0,len(_c_id),1):\n",
    "        ir_path = \"./*Dataset/\"+str(_obj_id)+\"/ir/\"+input_string+'_c'+str(_c_id[i])+'*'\n",
    "        ir_list.append(glob.glob(ir_path))\n",
    "    \n",
    "    \n",
    "    rgb_list = []\n",
    "    for i in range(0,len(_c_id),1):\n",
    "        rgb_path = \"./*Dataset/\"+str(_obj_id)+\"/rgb/\"+input_string+'_c'+str(_c_id[i])+'*'\n",
    "        rgb_list.append(glob.glob(rgb_path)[0])\n",
    "    \n",
    "    \n",
    "    output_dict = {'audio': audio_list,'calib':calib_list,'depth':depth_list,'imu':imu_list,'ir':ir_list,'rgb':rgb_list}\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from object id: `1`\n",
      "Extracting data from object id: `2`\n",
      "Extracting data from object id: `3`\n",
      "Extracting data from object id: `4`\n",
      "Extracting data from object id: `5`\n",
      "Extracting data from object id: `6`\n",
      "Extracting data from object id: `7`\n",
      "Failed...: (7, 'table_start', 'water', 'fifty', 'regular', 'light0')\n",
      "Failed...: (7, 'table_start', 'water', 'fifty', 'regular', 'light1')\n",
      "Failed...: (7, 'table_start', 'water', 'fifty', 'textured', 'light0')\n",
      "Failed...: (7, 'table_start', 'water', 'fifty', 'textured', 'light1')\n",
      "Failed...: (7, 'table_start', 'water', 'ninety', 'regular', 'light0')\n",
      "Failed...: (7, 'table_start', 'water', 'ninety', 'regular', 'light1')\n",
      "Failed...: (7, 'table_start', 'water', 'ninety', 'textured', 'light0')\n",
      "Failed...: (7, 'table_start', 'water', 'ninety', 'textured', 'light1')\n",
      "Failed...: (7, 'hand_start', 'water', 'fifty', 'regular', 'light0')\n",
      "Failed...: (7, 'hand_start', 'water', 'fifty', 'regular', 'light1')\n",
      "Failed...: (7, 'hand_start', 'water', 'fifty', 'textured', 'light0')\n",
      "Failed...: (7, 'hand_start', 'water', 'fifty', 'textured', 'light1')\n",
      "Failed...: (7, 'hand_start', 'water', 'ninety', 'regular', 'light0')\n",
      "Failed...: (7, 'hand_start', 'water', 'ninety', 'regular', 'light1')\n",
      "Failed...: (7, 'hand_start', 'water', 'ninety', 'textured', 'light0')\n",
      "Failed...: (7, 'hand_start', 'water', 'ninety', 'textured', 'light1')\n",
      "Failed...: (7, 'off_start', 'water', 'fifty', 'regular', 'light0')\n",
      "Failed...: (7, 'off_start', 'water', 'fifty', 'regular', 'light1')\n",
      "Failed...: (7, 'off_start', 'water', 'fifty', 'textured', 'light0')\n",
      "Failed...: (7, 'off_start', 'water', 'fifty', 'textured', 'light1')\n",
      "Failed...: (7, 'off_start', 'water', 'ninety', 'regular', 'light0')\n",
      "Failed...: (7, 'off_start', 'water', 'ninety', 'regular', 'light1')\n",
      "Failed...: (7, 'off_start', 'water', 'ninety', 'textured', 'light0')\n",
      "Failed...: (7, 'off_start', 'water', 'ninety', 'textured', 'light1')\n",
      "Extracting data from object id: `8`\n",
      "Failed...: (8, 'table_start', 'water', 'fifty', 'regular', 'light0')\n",
      "Failed...: (8, 'table_start', 'water', 'fifty', 'regular', 'light1')\n",
      "Failed...: (8, 'table_start', 'water', 'fifty', 'textured', 'light0')\n",
      "Failed...: (8, 'table_start', 'water', 'fifty', 'textured', 'light1')\n",
      "Failed...: (8, 'table_start', 'water', 'ninety', 'regular', 'light0')\n",
      "Failed...: (8, 'table_start', 'water', 'ninety', 'regular', 'light1')\n",
      "Failed...: (8, 'table_start', 'water', 'ninety', 'textured', 'light0')\n",
      "Failed...: (8, 'table_start', 'water', 'ninety', 'textured', 'light1')\n",
      "Failed...: (8, 'hand_start', 'water', 'fifty', 'regular', 'light0')\n",
      "Failed...: (8, 'hand_start', 'water', 'fifty', 'regular', 'light1')\n",
      "Failed...: (8, 'hand_start', 'water', 'fifty', 'textured', 'light0')\n",
      "Failed...: (8, 'hand_start', 'water', 'fifty', 'textured', 'light1')\n",
      "Failed...: (8, 'hand_start', 'water', 'ninety', 'regular', 'light0')\n",
      "Failed...: (8, 'hand_start', 'water', 'ninety', 'regular', 'light1')\n",
      "Failed...: (8, 'hand_start', 'water', 'ninety', 'textured', 'light0')\n",
      "Failed...: (8, 'hand_start', 'water', 'ninety', 'textured', 'light1')\n",
      "Failed...: (8, 'off_start', 'water', 'fifty', 'regular', 'light0')\n",
      "Failed...: (8, 'off_start', 'water', 'fifty', 'regular', 'light1')\n",
      "Failed...: (8, 'off_start', 'water', 'fifty', 'textured', 'light0')\n",
      "Failed...: (8, 'off_start', 'water', 'fifty', 'textured', 'light1')\n",
      "Failed...: (8, 'off_start', 'water', 'ninety', 'regular', 'light0')\n",
      "Failed...: (8, 'off_start', 'water', 'ninety', 'regular', 'light1')\n",
      "Failed...: (8, 'off_start', 'water', 'ninety', 'textured', 'light0')\n",
      "Failed...: (8, 'off_start', 'water', 'ninety', 'textured', 'light1')\n",
      "Extracting data from object id: `9`\n",
      "Failed...: (9, 'table_start', 'water', 'fifty', 'regular', 'light0')\n",
      "Failed...: (9, 'table_start', 'water', 'fifty', 'regular', 'light1')\n",
      "Failed...: (9, 'table_start', 'water', 'fifty', 'textured', 'light0')\n",
      "Failed...: (9, 'table_start', 'water', 'fifty', 'textured', 'light1')\n",
      "Failed...: (9, 'table_start', 'water', 'ninety', 'regular', 'light0')\n",
      "Failed...: (9, 'table_start', 'water', 'ninety', 'regular', 'light1')\n",
      "Failed...: (9, 'table_start', 'water', 'ninety', 'textured', 'light0')\n",
      "Failed...: (9, 'table_start', 'water', 'ninety', 'textured', 'light1')\n",
      "Failed...: (9, 'hand_start', 'water', 'fifty', 'regular', 'light0')\n",
      "Failed...: (9, 'hand_start', 'water', 'fifty', 'regular', 'light1')\n",
      "Failed...: (9, 'hand_start', 'water', 'fifty', 'textured', 'light0')\n",
      "Failed...: (9, 'hand_start', 'water', 'fifty', 'textured', 'light1')\n",
      "Failed...: (9, 'hand_start', 'water', 'ninety', 'regular', 'light0')\n",
      "Failed...: (9, 'hand_start', 'water', 'ninety', 'regular', 'light1')\n",
      "Failed...: (9, 'hand_start', 'water', 'ninety', 'textured', 'light0')\n",
      "Failed...: (9, 'hand_start', 'water', 'ninety', 'textured', 'light1')\n",
      "Failed...: (9, 'off_start', 'water', 'fifty', 'regular', 'light0')\n",
      "Failed...: (9, 'off_start', 'water', 'fifty', 'regular', 'light1')\n",
      "Failed...: (9, 'off_start', 'water', 'fifty', 'textured', 'light0')\n",
      "Failed...: (9, 'off_start', 'water', 'fifty', 'textured', 'light1')\n",
      "Failed...: (9, 'off_start', 'water', 'ninety', 'regular', 'light0')\n",
      "Failed...: (9, 'off_start', 'water', 'ninety', 'regular', 'light1')\n",
      "Failed...: (9, 'off_start', 'water', 'ninety', 'textured', 'light0')\n",
      "Failed...: (9, 'off_start', 'water', 'ninety', 'textured', 'light1')\n",
      "Got 684 samples in total.\n",
      "684 684\n",
      "torch.Size([684, 1501, 40])\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "N_MFCC = 40\n",
    "\n",
    "def load_and_extract_mfcc(path, window_size=20.0/1000, max_length=30):\n",
    "    # Load audio data from file\n",
    "    audio, sample_rate = librosa.load(path, res_type='kaiser_fast')\n",
    "    \n",
    "    length = audio.shape[0]\n",
    "    step_size = int(window_size * sample_rate) # In samples    \n",
    "    \n",
    "    # Retrieve the sequence of MFCCs\n",
    "    sequence = librosa.feature.mfcc(y=audio[:max_length*sample_rate], sr=sample_rate, n_mfcc=N_MFCC,\n",
    "                                    hop_length=step_size)\n",
    "    sequence = np.transpose(sequence)\n",
    "    \n",
    "    # Normalize the sequence according to its own data\n",
    "    ### Normalization for each MFCC individually\n",
    "    _mean = np.mean(sequence, axis=0)\n",
    "    _std = np.std(sequence, axis=0)\n",
    "    \n",
    "    return (sequence - _mean) / _std\n",
    "\n",
    "aux_dict = {'nothing': np.array([1., 0., 0., 0.]),\n",
    "            'pasta': np.array([0., 1., 0., 0.]),\n",
    "            'rice': np.array([0., 0., 1., 0.]),\n",
    "            'water': np.array([0., 0., 0., 1.])}\n",
    "data = []\n",
    "labels = []\n",
    "#LONGEST_SEQUENCE = 0\n",
    "for obj_id in range(1, 10):\n",
    "    print(f\"Extracting data from object id: `{obj_id}`\")\n",
    "    for sit in s_dict.keys():\n",
    "        for fi in fi_dict.keys():\n",
    "            for fu in fu_dict.keys():\n",
    "                for b in b_dict.keys():\n",
    "                    for l in l_dict.keys():\n",
    "                        try:\n",
    "                            sample = retrieve_data(obj_id, s=sit, fi=fi, fu=fu, b=b, l=l)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Failed...: {(obj_id, sit, fi, fu, b, l)}\")\n",
    "                        if sample != -1:\n",
    "                            seq_data = load_and_extract_mfcc(sample['audio'])\n",
    "                            data.append(torch.Tensor(seq_data))\n",
    "                            labels.append(fi_dict[fi])\n",
    "\n",
    "data = nn.utils.rnn.pad_sequence(data, batch_first=True, padding_value=0)\n",
    "#labels = torch.LongTensor(labels)\n",
    "N_SAMPLES = len(data)\n",
    "print(f\"Got {N_SAMPLES} samples in total.\")\n",
    "print(len(data), len(labels))\n",
    "print(data.shape)\n",
    "SEQUENCE_LENGTH = data.shape[1]\n",
    "SEQUENCE_FEATURES = data.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3] [108 216 216 144]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3] [ 99 196 190 130]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35871954 0.18118997 0.18691176 0.27317873]\n",
      "[0 1 2 3] [ 9 20 26 14]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Analyze class distribution and \n",
    "_classes, counts = np.unique(labels, return_counts=True)\n",
    "print(_classes, counts)\n",
    "plt.bar(_classes, counts)\n",
    "plt.title(\"Whole dataset\")\n",
    "plt.show()\n",
    "\n",
    "# Split in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels,\n",
    "                                                   test_size=0.1)\n",
    "\n",
    "_classes, counts = np.unique(y_train, return_counts=True)\n",
    "n_train_samples = len(y_train)\n",
    "print(_classes, counts)\n",
    "plt.bar(_classes, counts)\n",
    "plt.title(\"Train dataset\")\n",
    "plt.show()\n",
    "\n",
    "# Compute the class weights used for training\n",
    "CLASS_WEIGHTS = np.array([c / n_train_samples for c in counts])\n",
    "CLASS_WEIGHTS = 1.0 / CLASS_WEIGHTS\n",
    "CLASS_WEIGHTS = CLASS_WEIGHTS / CLASS_WEIGHTS.sum()\n",
    "print(CLASS_WEIGHTS)\n",
    "\n",
    "_classes, counts = np.unique(y_test, return_counts=True)\n",
    "print(_classes, counts)\n",
    "plt.bar(_classes, counts)\n",
    "plt.title(\"Test dataset\")\n",
    "plt.show()\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "        assert len(self.x) == len(self.y)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.Tensor(self.x[idx]), self.y[idx]\n",
    "    \n",
    "train_dataset = AudioDataset(X_train, y_train)\n",
    "test_dataset = AudioDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True,\n",
    "                          num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True,\n",
    "                          num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "[1, 35]: Loss: 2.7906\n",
      "Epoch 2\n",
      "[2, 35]: Loss: 2.7581\n",
      "Epoch 3\n",
      "[3, 35]: Loss: 2.7177\n",
      "Epoch 4\n",
      "[4, 35]: Loss: 2.6395\n",
      "Epoch 5\n",
      "[5, 35]: Loss: 2.5172\n",
      "Epoch 6\n",
      "[6, 35]: Loss: 2.3929\n",
      "Epoch 7\n",
      "[7, 35]: Loss: 2.2744\n",
      "Epoch 8\n",
      "[8, 35]: Loss: 2.1568\n",
      "Epoch 9\n",
      "[9, 35]: Loss: 1.9853\n",
      "Epoch 10\n",
      "[10, 35]: Loss: 1.8235\n",
      "69 69\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       1.00      0.78      0.88         9\n",
      "       pasta       0.50      0.85      0.63        20\n",
      "        rice       0.69      0.35      0.46        26\n",
      "       water       0.87      0.93      0.90        14\n",
      "\n",
      "    accuracy                           0.67        69\n",
      "   macro avg       0.76      0.73      0.72        69\n",
      "weighted avg       0.71      0.67      0.65        69\n",
      "\n",
      "Test Acc: 66.667%\n",
      "Epoch 11\n",
      "[11, 35]: Loss: 1.6903\n",
      "Epoch 12\n",
      "[12, 35]: Loss: 1.5719\n",
      "Epoch 13\n",
      "[13, 35]: Loss: 1.4688\n",
      "Epoch 14\n",
      "[14, 35]: Loss: 1.3373\n",
      "Epoch 15\n",
      "[15, 35]: Loss: 1.2191\n",
      "Epoch 16\n",
      "[16, 35]: Loss: 1.1032\n",
      "Epoch 17\n",
      "[17, 35]: Loss: 1.0529\n",
      "Epoch 18\n",
      "[18, 35]: Loss: 0.8888\n",
      "Epoch 19\n",
      "[19, 35]: Loss: 0.8085\n",
      "Epoch 20\n",
      "[20, 35]: Loss: 0.7367\n",
      "69 69\n",
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.75      1.00      0.86         9\n",
      "       pasta       0.72      0.90      0.80        20\n",
      "        rice       0.89      0.65      0.76        26\n",
      "       water       1.00      0.93      0.96        14\n",
      "\n",
      "    accuracy                           0.83        69\n",
      "   macro avg       0.84      0.87      0.84        69\n",
      "weighted avg       0.85      0.83      0.82        69\n",
      "\n",
      "Test Acc: 82.609%\n",
      "Epoch 21\n",
      "[21, 35]: Loss: 0.6790\n",
      "Epoch 22\n",
      "[22, 35]: Loss: 0.6132\n",
      "Epoch 23\n",
      "[23, 35]: Loss: 0.5649\n",
      "Epoch 24\n",
      "[24, 35]: Loss: 0.5446\n",
      "Epoch 25\n",
      "[25, 35]: Loss: 0.5030\n",
      "Epoch 26\n",
      "[26, 35]: Loss: 0.4530\n",
      "Epoch 27\n",
      "[27, 35]: Loss: 0.4397\n",
      "Epoch 28\n",
      "[28, 35]: Loss: 0.4421\n",
      "Epoch 29\n",
      "[29, 35]: Loss: 0.3816\n",
      "Epoch 30\n",
      "[30, 35]: Loss: 0.4124\n",
      "69 69\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.64      1.00      0.78         9\n",
      "       pasta       0.81      0.85      0.83        20\n",
      "        rice       0.91      0.77      0.83        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.84        69\n",
      "   macro avg       0.84      0.87      0.84        69\n",
      "weighted avg       0.86      0.84      0.84        69\n",
      "\n",
      "Test Acc: 84.058%\n",
      "Epoch 31\n",
      "[31, 35]: Loss: 0.3618\n",
      "Epoch 32\n",
      "[32, 35]: Loss: 0.3743\n",
      "Epoch 33\n",
      "[33, 35]: Loss: 0.3503\n",
      "Epoch 34\n",
      "[34, 35]: Loss: 0.3358\n",
      "Epoch 35\n",
      "[35, 35]: Loss: 0.3005\n",
      "Epoch 36\n",
      "[36, 35]: Loss: 0.2669\n",
      "Epoch 37\n",
      "[37, 35]: Loss: 0.2970\n",
      "Epoch 38\n",
      "[38, 35]: Loss: 0.2805\n",
      "Epoch 39\n",
      "[39, 35]: Loss: 0.2640\n",
      "Epoch 40\n",
      "[40, 35]: Loss: 0.2666\n",
      "69 69\n",
      "1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.69      1.00      0.82         9\n",
      "       pasta       0.81      0.85      0.83        20\n",
      "        rice       0.91      0.81      0.86        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.86        69\n",
      "   macro avg       0.85      0.88      0.86        69\n",
      "weighted avg       0.87      0.86      0.86        69\n",
      "\n",
      "Test Acc: 85.507%\n",
      "Epoch 41\n",
      "[41, 35]: Loss: 0.2456\n",
      "Epoch 42\n",
      "[42, 35]: Loss: 0.2412\n",
      "Epoch 43\n",
      "[43, 35]: Loss: 0.2064\n",
      "Epoch 44\n",
      "[44, 35]: Loss: 0.2063\n",
      "Epoch 45\n",
      "[45, 35]: Loss: 0.1852\n",
      "Epoch 46\n",
      "[46, 35]: Loss: 0.2031\n",
      "Epoch 47\n",
      "[47, 35]: Loss: 0.1863\n",
      "Epoch 48\n",
      "[48, 35]: Loss: 0.1727\n",
      "Epoch 49\n",
      "[49, 35]: Loss: 0.1749\n",
      "Epoch 50\n",
      "[50, 35]: Loss: 0.1681\n",
      "69 69\n",
      "1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.64      1.00      0.78         9\n",
      "       pasta       0.85      0.85      0.85        20\n",
      "        rice       0.91      0.81      0.86        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.86        69\n",
      "   macro avg       0.85      0.88      0.85        69\n",
      "weighted avg       0.88      0.86      0.86        69\n",
      "\n",
      "Test Acc: 85.507%\n",
      "Epoch 51\n",
      "[51, 35]: Loss: 0.1678\n",
      "Epoch 52\n",
      "[52, 35]: Loss: 0.1524\n",
      "Epoch 53\n",
      "[53, 35]: Loss: 0.1451\n",
      "Epoch 54\n",
      "[54, 35]: Loss: 0.1419\n",
      "Epoch 55\n",
      "[55, 35]: Loss: 0.1676\n",
      "Epoch 56\n",
      "[56, 35]: Loss: 0.1452\n",
      "Epoch 57\n",
      "[57, 35]: Loss: 0.1371\n",
      "Epoch 58\n",
      "[58, 35]: Loss: 0.1139\n",
      "Epoch 59\n",
      "[59, 35]: Loss: 0.1062\n",
      "Epoch 60\n",
      "[60, 35]: Loss: 0.1199\n",
      "69 69\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.69      1.00      0.82         9\n",
      "       pasta       0.86      0.90      0.88        20\n",
      "        rice       0.91      0.81      0.86        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.87        69\n",
      "   macro avg       0.87      0.89      0.87        69\n",
      "weighted avg       0.89      0.87      0.87        69\n",
      "\n",
      "Test Acc: 86.957%\n",
      "Epoch 61\n",
      "[61, 35]: Loss: 0.1231\n",
      "Epoch 62\n",
      "[62, 35]: Loss: 0.1100\n",
      "Epoch 63\n",
      "[63, 35]: Loss: 0.1379\n",
      "Epoch 64\n",
      "[64, 35]: Loss: 0.1099\n",
      "Epoch 65\n",
      "[65, 35]: Loss: 0.1244\n",
      "Epoch 66\n",
      "[66, 35]: Loss: 0.1093\n",
      "Epoch 67\n",
      "[67, 35]: Loss: 0.1149\n",
      "Epoch 68\n",
      "[68, 35]: Loss: 0.0914\n",
      "Epoch 69\n",
      "[69, 35]: Loss: 0.0942\n",
      "Epoch 70\n",
      "[70, 35]: Loss: 0.0817\n",
      "69 69\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.64      1.00      0.78         9\n",
      "       pasta       0.85      0.85      0.85        20\n",
      "        rice       0.91      0.81      0.86        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.86        69\n",
      "   macro avg       0.85      0.88      0.85        69\n",
      "weighted avg       0.88      0.86      0.86        69\n",
      "\n",
      "Test Acc: 85.507%\n",
      "Epoch 71\n",
      "[71, 35]: Loss: 0.0872\n",
      "Epoch 72\n",
      "[72, 35]: Loss: 0.0998\n",
      "Epoch 73\n",
      "[73, 35]: Loss: 0.0744\n",
      "Epoch 74\n",
      "[74, 35]: Loss: 0.0669\n",
      "Epoch 75\n",
      "[75, 35]: Loss: 0.0904\n",
      "Epoch 76\n",
      "[76, 35]: Loss: 0.0764\n",
      "Epoch 77\n",
      "[77, 35]: Loss: 0.0760\n",
      "Epoch 78\n",
      "[78, 35]: Loss: 0.0742\n",
      "Epoch 79\n",
      "[79, 35]: Loss: 0.0551\n",
      "Epoch 80\n",
      "[80, 35]: Loss: 0.0737\n",
      "69 69\n",
      "1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.69      1.00      0.82         9\n",
      "       pasta       0.90      0.90      0.90        20\n",
      "        rice       0.92      0.85      0.88        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.88        69\n",
      "   macro avg       0.88      0.90      0.88        69\n",
      "weighted avg       0.90      0.88      0.89        69\n",
      "\n",
      "Test Acc: 88.406%\n",
      "Epoch 81\n",
      "[81, 35]: Loss: 0.0629\n",
      "Epoch 82\n",
      "[82, 35]: Loss: 0.0670\n",
      "Epoch 83\n",
      "[83, 35]: Loss: 0.0537\n",
      "Epoch 84\n",
      "[84, 35]: Loss: 0.0621\n",
      "Epoch 85\n",
      "[85, 35]: Loss: 0.0589\n",
      "Epoch 86\n",
      "[86, 35]: Loss: 0.0589\n",
      "Epoch 87\n",
      "[87, 35]: Loss: 0.0575\n",
      "Epoch 88\n",
      "[88, 35]: Loss: 0.0609\n",
      "Epoch 89\n",
      "[89, 35]: Loss: 0.0515\n",
      "Epoch 90\n",
      "[90, 35]: Loss: 0.0480\n",
      "69 69\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.69      1.00      0.82         9\n",
      "       pasta       0.90      0.90      0.90        20\n",
      "        rice       0.92      0.85      0.88        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.88        69\n",
      "   macro avg       0.88      0.90      0.88        69\n",
      "weighted avg       0.90      0.88      0.89        69\n",
      "\n",
      "Test Acc: 88.406%\n",
      "Epoch 91\n",
      "[91, 35]: Loss: 0.0480\n",
      "Epoch 92\n",
      "[92, 35]: Loss: 0.0507\n",
      "Epoch 93\n",
      "[93, 35]: Loss: 0.0456\n",
      "Epoch 94\n",
      "[94, 35]: Loss: 0.0444\n",
      "Epoch 95\n",
      "[95, 35]: Loss: 0.0364\n",
      "Epoch 96\n",
      "[96, 35]: Loss: 0.0351\n",
      "Epoch 97\n",
      "[97, 35]: Loss: 0.0419\n",
      "Epoch 98\n",
      "[98, 35]: Loss: 0.0337\n",
      "Epoch 99\n",
      "[99, 35]: Loss: 0.0482\n",
      "Epoch 100\n",
      "[100, 35]: Loss: 0.0439\n",
      "69 69\n",
      "1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.64      1.00      0.78         9\n",
      "       pasta       0.94      0.85      0.89        20\n",
      "        rice       0.92      0.88      0.90        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.88        69\n",
      "   macro avg       0.88      0.90      0.88        69\n",
      "weighted avg       0.91      0.88      0.89        69\n",
      "\n",
      "Test Acc: 88.406%\n",
      "Epoch 101\n",
      "[101, 35]: Loss: 0.0336\n",
      "Epoch 102\n",
      "[102, 35]: Loss: 0.0413\n",
      "Epoch 103\n",
      "[103, 35]: Loss: 0.0442\n",
      "Epoch 104\n",
      "[104, 35]: Loss: 0.0389\n",
      "Epoch 105\n",
      "[105, 35]: Loss: 0.0333\n",
      "Epoch 106\n",
      "[106, 35]: Loss: 0.0340\n",
      "Epoch 107\n",
      "[107, 35]: Loss: 0.0314\n",
      "Epoch 108\n",
      "[108, 35]: Loss: 0.0291\n",
      "Epoch 109\n",
      "[109, 35]: Loss: 0.0264\n",
      "Epoch 110\n",
      "[110, 35]: Loss: 0.0279\n",
      "69 69\n",
      "1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.64      1.00      0.78         9\n",
      "       pasta       0.94      0.85      0.89        20\n",
      "        rice       0.92      0.88      0.90        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.88        69\n",
      "   macro avg       0.88      0.90      0.88        69\n",
      "weighted avg       0.91      0.88      0.89        69\n",
      "\n",
      "Test Acc: 88.406%\n",
      "Epoch 111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[111, 35]: Loss: 0.0219\n",
      "Epoch 112\n",
      "[112, 35]: Loss: 0.0246\n",
      "Epoch 113\n",
      "[113, 35]: Loss: 0.0348\n",
      "Epoch 114\n",
      "[114, 35]: Loss: 0.0182\n",
      "Epoch 115\n",
      "[115, 35]: Loss: 0.0332\n",
      "Epoch 116\n",
      "[116, 35]: Loss: 0.0453\n",
      "Epoch 117\n",
      "[117, 35]: Loss: 0.0269\n",
      "Epoch 118\n",
      "[118, 35]: Loss: 0.0261\n",
      "Epoch 119\n",
      "[119, 35]: Loss: 0.0226\n",
      "Epoch 120\n",
      "[120, 35]: Loss: 0.0219\n",
      "69 69\n",
      "3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.69      1.00      0.82         9\n",
      "       pasta       0.95      0.95      0.95        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.91        69\n",
      "   macro avg       0.90      0.92      0.90        69\n",
      "weighted avg       0.93      0.91      0.92        69\n",
      "\n",
      "Test Acc: 91.304%\n",
      "Epoch 121\n",
      "[121, 35]: Loss: 0.0215\n",
      "Epoch 122\n",
      "[122, 35]: Loss: 0.0454\n",
      "Epoch 123\n",
      "[123, 35]: Loss: 0.0226\n",
      "Epoch 124\n",
      "[124, 35]: Loss: 0.0242\n",
      "Epoch 125\n",
      "[125, 35]: Loss: 0.0232\n",
      "Epoch 126\n",
      "[126, 35]: Loss: 0.0283\n",
      "Epoch 127\n",
      "[127, 35]: Loss: 0.0256\n",
      "Epoch 128\n",
      "[128, 35]: Loss: 0.0202\n",
      "Epoch 129\n",
      "[129, 35]: Loss: 0.0304\n",
      "Epoch 130\n",
      "[130, 35]: Loss: 0.0305\n",
      "69 69\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.69      1.00      0.82         9\n",
      "       pasta       0.90      0.95      0.93        20\n",
      "        rice       0.96      0.85      0.90        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.90        69\n",
      "   macro avg       0.89      0.91      0.89        69\n",
      "weighted avg       0.92      0.90      0.90        69\n",
      "\n",
      "Test Acc: 89.855%\n",
      "Epoch 131\n",
      "[131, 35]: Loss: 0.0260\n",
      "Epoch 132\n",
      "[132, 35]: Loss: 0.0296\n",
      "Epoch 133\n",
      "[133, 35]: Loss: 0.0308\n",
      "Epoch 134\n",
      "[134, 35]: Loss: 0.0175\n",
      "Epoch 135\n",
      "[135, 35]: Loss: 0.0192\n",
      "Epoch 136\n",
      "[136, 35]: Loss: 0.0159\n",
      "Epoch 137\n",
      "[137, 35]: Loss: 0.0240\n",
      "Epoch 138\n",
      "[138, 35]: Loss: 0.0248\n",
      "Epoch 139\n",
      "[139, 35]: Loss: 0.0218\n",
      "Epoch 140\n",
      "[140, 35]: Loss: 0.0150\n",
      "69 69\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.64      1.00      0.78         9\n",
      "       pasta       0.94      0.85      0.89        20\n",
      "        rice       0.92      0.88      0.90        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.88        69\n",
      "   macro avg       0.88      0.90      0.88        69\n",
      "weighted avg       0.91      0.88      0.89        69\n",
      "\n",
      "Test Acc: 88.406%\n",
      "Epoch 141\n",
      "[141, 35]: Loss: 0.0177\n",
      "Epoch 142\n",
      "[142, 35]: Loss: 0.0141\n",
      "Epoch 143\n",
      "[143, 35]: Loss: 0.0179\n",
      "Epoch 144\n",
      "[144, 35]: Loss: 0.0269\n",
      "Epoch 145\n",
      "[145, 35]: Loss: 0.0153\n",
      "Epoch 146\n",
      "[146, 35]: Loss: 0.0173\n",
      "Epoch 147\n",
      "[147, 35]: Loss: 0.0191\n",
      "Epoch 148\n",
      "[148, 35]: Loss: 0.0206\n",
      "Epoch 149\n",
      "[149, 35]: Loss: 0.0318\n",
      "Epoch 150\n",
      "[150, 35]: Loss: 0.0170\n",
      "69 69\n",
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.75      1.00      0.86         9\n",
      "       pasta       0.95      0.90      0.92        20\n",
      "        rice       0.92      0.92      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.91        69\n",
      "   macro avg       0.91      0.92      0.91        69\n",
      "weighted avg       0.92      0.91      0.91        69\n",
      "\n",
      "Test Acc: 91.304%\n",
      "Epoch 151\n",
      "[151, 35]: Loss: 0.0204\n",
      "Epoch 152\n",
      "[152, 35]: Loss: 0.0213\n",
      "Epoch 153\n",
      "[153, 35]: Loss: 0.0133\n",
      "Epoch 154\n",
      "[154, 35]: Loss: 0.0172\n",
      "Epoch 155\n",
      "[155, 35]: Loss: 0.0164\n",
      "Epoch 156\n",
      "[156, 35]: Loss: 0.0173\n",
      "Epoch 157\n",
      "[157, 35]: Loss: 0.0146\n",
      "Epoch 158\n",
      "[158, 35]: Loss: 0.0131\n",
      "Epoch 159\n",
      "[159, 35]: Loss: 0.0171\n",
      "Epoch 160\n",
      "[160, 35]: Loss: 0.0147\n",
      "69 69\n",
      "3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.69      1.00      0.82         9\n",
      "       pasta       0.95      0.90      0.92        20\n",
      "        rice       0.92      0.88      0.90        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.90        69\n",
      "   macro avg       0.89      0.91      0.89        69\n",
      "weighted avg       0.91      0.90      0.90        69\n",
      "\n",
      "Test Acc: 89.855%\n",
      "Epoch 161\n",
      "[161, 35]: Loss: 0.0167\n",
      "Epoch 162\n",
      "[162, 35]: Loss: 0.0130\n",
      "Epoch 163\n",
      "[163, 35]: Loss: 0.0159\n",
      "Epoch 164\n",
      "[164, 35]: Loss: 0.0241\n",
      "Epoch 165\n",
      "[165, 35]: Loss: 0.0148\n",
      "Epoch 166\n",
      "[166, 35]: Loss: 0.0115\n",
      "Epoch 167\n",
      "[167, 35]: Loss: 0.0084\n",
      "Epoch 168\n",
      "[168, 35]: Loss: 0.0137\n",
      "Epoch 169\n",
      "[169, 35]: Loss: 0.0113\n",
      "Epoch 170\n",
      "[170, 35]: Loss: 0.0095\n",
      "69 69\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.69      1.00      0.82         9\n",
      "       pasta       0.95      0.95      0.95        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.91        69\n",
      "   macro avg       0.90      0.92      0.90        69\n",
      "weighted avg       0.93      0.91      0.92        69\n",
      "\n",
      "Test Acc: 91.304%\n",
      "Epoch 171\n",
      "[171, 35]: Loss: 0.0085\n",
      "Epoch 172\n",
      "[172, 35]: Loss: 0.0161\n",
      "Epoch 173\n",
      "[173, 35]: Loss: 0.0115\n",
      "Epoch 174\n",
      "[174, 35]: Loss: 0.0206\n",
      "Epoch 175\n",
      "[175, 35]: Loss: 0.0117\n",
      "Epoch 176\n",
      "[176, 35]: Loss: 0.0154\n",
      "Epoch 177\n",
      "[177, 35]: Loss: 0.0087\n",
      "Epoch 178\n",
      "[178, 35]: Loss: 0.0084\n",
      "Epoch 179\n",
      "[179, 35]: Loss: 0.0095\n",
      "Epoch 180\n",
      "[180, 35]: Loss: 0.0073\n",
      "69 69\n",
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.69      1.00      0.82         9\n",
      "       pasta       0.95      0.95      0.95        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.91        69\n",
      "   macro avg       0.90      0.92      0.90        69\n",
      "weighted avg       0.93      0.91      0.92        69\n",
      "\n",
      "Test Acc: 91.304%\n",
      "Epoch 181\n",
      "[181, 35]: Loss: 0.0103\n",
      "Epoch 182\n",
      "[182, 35]: Loss: 0.0088\n",
      "Epoch 183\n",
      "[183, 35]: Loss: 0.0107\n",
      "Epoch 184\n",
      "[184, 35]: Loss: 0.0080\n",
      "Epoch 185\n",
      "[185, 35]: Loss: 0.0119\n",
      "Epoch 186\n",
      "[186, 35]: Loss: 0.0089\n",
      "Epoch 187\n",
      "[187, 35]: Loss: 0.0111\n",
      "Epoch 188\n",
      "[188, 35]: Loss: 0.0106\n",
      "Epoch 189\n",
      "[189, 35]: Loss: 0.0111\n",
      "Epoch 190\n",
      "[190, 35]: Loss: 0.0059\n",
      "69 69\n",
      "3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.69      1.00      0.82         9\n",
      "       pasta       0.95      0.90      0.92        20\n",
      "        rice       0.92      0.88      0.90        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.90        69\n",
      "   macro avg       0.89      0.91      0.89        69\n",
      "weighted avg       0.91      0.90      0.90        69\n",
      "\n",
      "Test Acc: 89.855%\n",
      "Epoch 191\n",
      "[191, 35]: Loss: 0.0100\n",
      "Epoch 192\n",
      "[192, 35]: Loss: 0.0101\n",
      "Epoch 193\n",
      "[193, 35]: Loss: 0.0120\n",
      "Epoch 194\n",
      "[194, 35]: Loss: 0.0156\n",
      "Epoch 195\n",
      "[195, 35]: Loss: 0.0110\n",
      "Epoch 196\n",
      "[196, 35]: Loss: 0.0131\n",
      "Epoch 197\n",
      "[197, 35]: Loss: 0.0087\n",
      "Epoch 198\n",
      "[198, 35]: Loss: 0.0087\n",
      "Epoch 199\n",
      "[199, 35]: Loss: 0.0069\n",
      "Epoch 200\n",
      "[200, 35]: Loss: 0.0071\n",
      "69 69\n",
      "3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.69      1.00      0.82         9\n",
      "       pasta       0.95      0.95      0.95        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.91        69\n",
      "   macro avg       0.90      0.92      0.90        69\n",
      "weighted avg       0.93      0.91      0.92        69\n",
      "\n",
      "Test Acc: 91.304%\n",
      "Epoch 201\n",
      "[201, 35]: Loss: 0.0079\n",
      "Epoch 202\n",
      "[202, 35]: Loss: 0.0054\n",
      "Epoch 203\n",
      "[203, 35]: Loss: 0.0066\n",
      "Epoch 204\n",
      "[204, 35]: Loss: 0.0084\n",
      "Epoch 205\n",
      "[205, 35]: Loss: 0.0064\n",
      "Epoch 206\n",
      "[206, 35]: Loss: 0.0125\n",
      "Epoch 207\n",
      "[207, 35]: Loss: 0.0060\n",
      "Epoch 208\n",
      "[208, 35]: Loss: 0.0067\n",
      "Epoch 209\n",
      "[209, 35]: Loss: 0.0060\n",
      "Epoch 210\n",
      "[210, 35]: Loss: 0.0074\n",
      "69 69\n",
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.69      1.00      0.82         9\n",
      "       pasta       0.95      0.95      0.95        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.91        69\n",
      "   macro avg       0.90      0.92      0.90        69\n",
      "weighted avg       0.93      0.91      0.92        69\n",
      "\n",
      "Test Acc: 91.304%\n",
      "Epoch 211\n",
      "[211, 35]: Loss: 0.0066\n",
      "Epoch 212\n",
      "[212, 35]: Loss: 0.0087\n",
      "Epoch 213\n",
      "[213, 35]: Loss: 0.0062\n",
      "Epoch 214\n",
      "[214, 35]: Loss: 0.0127\n",
      "Epoch 215\n",
      "[215, 35]: Loss: 0.0104\n",
      "Epoch 216\n",
      "[216, 35]: Loss: 0.0058\n",
      "Epoch 217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[217, 35]: Loss: 0.0078\n",
      "Epoch 218\n",
      "[218, 35]: Loss: 0.0082\n",
      "Epoch 219\n",
      "[219, 35]: Loss: 0.0071\n",
      "Epoch 220\n",
      "[220, 35]: Loss: 0.0085\n",
      "69 69\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.69      1.00      0.82         9\n",
      "       pasta       0.95      0.95      0.95        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.91        69\n",
      "   macro avg       0.90      0.92      0.90        69\n",
      "weighted avg       0.93      0.91      0.92        69\n",
      "\n",
      "Test Acc: 91.304%\n",
      "Epoch 221\n",
      "[221, 35]: Loss: 0.0047\n",
      "Epoch 222\n",
      "[222, 35]: Loss: 0.0070\n",
      "Epoch 223\n",
      "[223, 35]: Loss: 0.0098\n",
      "Epoch 224\n",
      "[224, 35]: Loss: 0.0096\n",
      "Epoch 225\n",
      "[225, 35]: Loss: 0.0062\n",
      "Epoch 226\n",
      "[226, 35]: Loss: 0.0070\n",
      "Epoch 227\n",
      "[227, 35]: Loss: 0.0093\n",
      "Epoch 228\n",
      "[228, 35]: Loss: 0.0108\n",
      "Epoch 229\n",
      "[229, 35]: Loss: 0.0098\n",
      "Epoch 230\n",
      "[230, 35]: Loss: 0.0107\n",
      "69 69\n",
      "1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.69      1.00      0.82         9\n",
      "       pasta       0.95      0.95      0.95        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.91        69\n",
      "   macro avg       0.90      0.92      0.90        69\n",
      "weighted avg       0.93      0.91      0.92        69\n",
      "\n",
      "Test Acc: 91.304%\n",
      "Epoch 231\n",
      "[231, 35]: Loss: 0.0063\n",
      "Epoch 232\n",
      "[232, 35]: Loss: 0.0082\n",
      "Epoch 233\n",
      "[233, 35]: Loss: 0.0068\n",
      "Epoch 234\n",
      "[234, 35]: Loss: 0.0084\n",
      "Epoch 235\n",
      "[235, 35]: Loss: 0.0063\n",
      "Epoch 236\n",
      "[236, 35]: Loss: 0.0047\n",
      "Epoch 237\n",
      "[237, 35]: Loss: 0.0058\n",
      "Epoch 238\n",
      "[238, 35]: Loss: 0.0105\n",
      "Epoch 239\n",
      "[239, 35]: Loss: 0.0108\n",
      "Epoch 240\n",
      "[240, 35]: Loss: 0.0147\n",
      "69 69\n",
      "3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.69      1.00      0.82         9\n",
      "       pasta       0.95      0.95      0.95        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.91        69\n",
      "   macro avg       0.90      0.92      0.90        69\n",
      "weighted avg       0.93      0.91      0.92        69\n",
      "\n",
      "Test Acc: 91.304%\n",
      "Epoch 241\n",
      "[241, 35]: Loss: 0.0055\n",
      "Epoch 242\n",
      "[242, 35]: Loss: 0.0062\n",
      "Epoch 243\n",
      "[243, 35]: Loss: 0.0039\n",
      "Epoch 244\n",
      "[244, 35]: Loss: 0.0076\n",
      "Epoch 245\n",
      "[245, 35]: Loss: 0.0098\n",
      "Epoch 246\n",
      "[246, 35]: Loss: 0.0061\n",
      "Epoch 247\n",
      "[247, 35]: Loss: 0.0046\n",
      "Epoch 248\n",
      "[248, 35]: Loss: 0.0054\n",
      "Epoch 249\n",
      "[249, 35]: Loss: 0.0068\n",
      "Epoch 250\n",
      "[250, 35]: Loss: 0.0055\n",
      "69 69\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.69      1.00      0.82         9\n",
      "       pasta       0.95      0.95      0.95        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.91        69\n",
      "   macro avg       0.90      0.92      0.90        69\n",
      "weighted avg       0.93      0.91      0.92        69\n",
      "\n",
      "Test Acc: 91.304%\n",
      "Epoch 251\n",
      "[251, 35]: Loss: 0.0049\n",
      "Epoch 252\n",
      "[252, 35]: Loss: 0.0059\n",
      "Epoch 253\n",
      "[253, 35]: Loss: 0.0085\n",
      "Epoch 254\n",
      "[254, 35]: Loss: 0.0039\n",
      "Epoch 255\n",
      "[255, 35]: Loss: 0.0042\n",
      "Epoch 256\n",
      "[256, 35]: Loss: 0.0037\n",
      "Epoch 257\n",
      "[257, 35]: Loss: 0.0053\n",
      "Epoch 258\n",
      "[258, 35]: Loss: 0.0096\n",
      "Epoch 259\n",
      "[259, 35]: Loss: 0.0055\n",
      "Epoch 260\n",
      "[260, 35]: Loss: 0.0068\n",
      "69 69\n",
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.69      1.00      0.82         9\n",
      "       pasta       0.95      0.95      0.95        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.91        69\n",
      "   macro avg       0.90      0.92      0.90        69\n",
      "weighted avg       0.93      0.91      0.92        69\n",
      "\n",
      "Test Acc: 91.304%\n",
      "Epoch 261\n",
      "[261, 35]: Loss: 0.0042\n",
      "Epoch 262\n",
      "[262, 35]: Loss: 0.0121\n",
      "Epoch 263\n",
      "[263, 35]: Loss: 0.0103\n",
      "Epoch 264\n",
      "[264, 35]: Loss: 0.0075\n",
      "Epoch 265\n",
      "[265, 35]: Loss: 0.0049\n",
      "Epoch 266\n",
      "[266, 35]: Loss: 0.0044\n",
      "Epoch 267\n",
      "[267, 35]: Loss: 0.0042\n",
      "Epoch 268\n",
      "[268, 35]: Loss: 0.0056\n",
      "Epoch 269\n",
      "[269, 35]: Loss: 0.0034\n",
      "Epoch 270\n",
      "[270, 35]: Loss: 0.0048\n",
      "69 69\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.69      1.00      0.82         9\n",
      "       pasta       0.95      0.95      0.95        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.91        69\n",
      "   macro avg       0.90      0.92      0.90        69\n",
      "weighted avg       0.93      0.91      0.92        69\n",
      "\n",
      "Test Acc: 91.304%\n",
      "Epoch 271\n",
      "[271, 35]: Loss: 0.0076\n",
      "Epoch 272\n",
      "[272, 35]: Loss: 0.0056\n",
      "Epoch 273\n",
      "[273, 35]: Loss: 0.0082\n",
      "Epoch 274\n",
      "[274, 35]: Loss: 0.0091\n",
      "Epoch 275\n",
      "[275, 35]: Loss: 0.0071\n",
      "Epoch 276\n",
      "[276, 35]: Loss: 0.0056\n",
      "Epoch 277\n",
      "[277, 35]: Loss: 0.0032\n",
      "Epoch 278\n",
      "[278, 35]: Loss: 0.0050\n",
      "Epoch 279\n",
      "[279, 35]: Loss: 0.0042\n",
      "Epoch 280\n",
      "[280, 35]: Loss: 0.0041\n",
      "69 69\n",
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.69      1.00      0.82         9\n",
      "       pasta       0.95      0.95      0.95        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.91        69\n",
      "   macro avg       0.90      0.92      0.90        69\n",
      "weighted avg       0.93      0.91      0.92        69\n",
      "\n",
      "Test Acc: 91.304%\n",
      "Epoch 281\n",
      "[281, 35]: Loss: 0.0243\n",
      "Epoch 282\n",
      "[282, 35]: Loss: 0.0055\n",
      "Epoch 283\n",
      "[283, 35]: Loss: 0.0049\n",
      "Epoch 284\n",
      "[284, 35]: Loss: 0.0074\n",
      "Epoch 285\n",
      "[285, 35]: Loss: 0.0067\n",
      "Epoch 286\n",
      "[286, 35]: Loss: 0.0047\n",
      "Epoch 287\n",
      "[287, 35]: Loss: 0.0058\n",
      "Epoch 288\n",
      "[288, 35]: Loss: 0.0051\n",
      "Epoch 289\n",
      "[289, 35]: Loss: 0.0055\n",
      "Epoch 290\n",
      "[290, 35]: Loss: 0.0044\n",
      "69 69\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.69      1.00      0.82         9\n",
      "       pasta       0.95      0.95      0.95        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.91        69\n",
      "   macro avg       0.90      0.92      0.90        69\n",
      "weighted avg       0.93      0.91      0.92        69\n",
      "\n",
      "Test Acc: 91.304%\n",
      "Epoch 291\n",
      "[291, 35]: Loss: 0.0040\n",
      "Epoch 292\n",
      "[292, 35]: Loss: 0.0052\n",
      "Epoch 293\n",
      "[293, 35]: Loss: 0.0095\n",
      "Epoch 294\n",
      "[294, 35]: Loss: 0.0043\n",
      "Epoch 295\n",
      "[295, 35]: Loss: 0.0067\n",
      "Epoch 296\n",
      "[296, 35]: Loss: 0.0027\n",
      "Epoch 297\n",
      "[297, 35]: Loss: 0.0034\n",
      "Epoch 298\n",
      "[298, 35]: Loss: 0.0032\n",
      "Epoch 299\n",
      "[299, 35]: Loss: 0.0040\n",
      "Epoch 300\n",
      "[300, 35]: Loss: 0.0030\n",
      "69 69\n",
      "3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.69      1.00      0.82         9\n",
      "       pasta       0.95      0.95      0.95        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.91        69\n",
      "   macro avg       0.90      0.92      0.90        69\n",
      "weighted avg       0.93      0.91      0.92        69\n",
      "\n",
      "Test Acc: 91.304%\n",
      "Epoch 301\n",
      "[301, 35]: Loss: 0.0055\n",
      "Epoch 302\n",
      "[302, 35]: Loss: 0.0055\n",
      "Epoch 303\n",
      "[303, 35]: Loss: 0.0031\n",
      "Epoch 304\n",
      "[304, 35]: Loss: 0.0032\n",
      "Epoch 305\n",
      "[305, 35]: Loss: 0.0038\n",
      "Epoch 306\n",
      "[306, 35]: Loss: 0.0039\n",
      "Epoch 307\n",
      "[307, 35]: Loss: 0.0033\n",
      "Epoch 308\n",
      "[308, 35]: Loss: 0.0045\n",
      "Epoch 309\n",
      "[309, 35]: Loss: 0.0055\n",
      "Epoch 310\n",
      "[310, 35]: Loss: 0.0029\n",
      "69 69\n",
      "1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.69      1.00      0.82         9\n",
      "       pasta       0.95      0.95      0.95        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.91        69\n",
      "   macro avg       0.90      0.92      0.90        69\n",
      "weighted avg       0.93      0.91      0.92        69\n",
      "\n",
      "Test Acc: 91.304%\n",
      "Epoch 311\n",
      "[311, 35]: Loss: 0.0048\n",
      "Epoch 312\n",
      "[312, 35]: Loss: 0.0037\n",
      "Epoch 313\n",
      "[313, 35]: Loss: 0.0031\n",
      "Epoch 314\n",
      "[314, 35]: Loss: 0.0043\n",
      "Epoch 315\n",
      "[315, 35]: Loss: 0.0042\n",
      "Epoch 316\n",
      "[316, 35]: Loss: 0.0028\n",
      "Epoch 317\n",
      "[317, 35]: Loss: 0.0042\n",
      "Epoch 318\n",
      "[318, 35]: Loss: 0.0049\n",
      "Epoch 319\n",
      "[319, 35]: Loss: 0.0059\n",
      "Epoch 320\n",
      "[320, 35]: Loss: 0.0106\n",
      "69 69\n",
      "3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.69      1.00      0.82         9\n",
      "       pasta       0.95      0.95      0.95        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.91        69\n",
      "   macro avg       0.90      0.92      0.90        69\n",
      "weighted avg       0.93      0.91      0.92        69\n",
      "\n",
      "Test Acc: 91.304%\n",
      "Epoch 321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[321, 35]: Loss: 0.0056\n",
      "Epoch 322\n",
      "[322, 35]: Loss: 0.0062\n",
      "Epoch 323\n",
      "[323, 35]: Loss: 0.0055\n",
      "Epoch 324\n",
      "[324, 35]: Loss: 0.0039\n",
      "Epoch 325\n",
      "[325, 35]: Loss: 0.0030\n",
      "Epoch 326\n",
      "[326, 35]: Loss: 0.0046\n",
      "Epoch 327\n",
      "[327, 35]: Loss: 0.0053\n",
      "Epoch 328\n",
      "[328, 35]: Loss: 0.0033\n",
      "Epoch 329\n",
      "[329, 35]: Loss: 0.0058\n",
      "Epoch 330\n",
      "[330, 35]: Loss: 0.0038\n",
      "69 69\n",
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.69      1.00      0.82         9\n",
      "       pasta       0.95      0.95      0.95        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.91        69\n",
      "   macro avg       0.90      0.92      0.90        69\n",
      "weighted avg       0.93      0.91      0.92        69\n",
      "\n",
      "Test Acc: 91.304%\n",
      "Epoch 331\n",
      "[331, 35]: Loss: 0.0061\n",
      "Epoch 332\n",
      "[332, 35]: Loss: 0.0062\n",
      "Epoch 333\n",
      "[333, 35]: Loss: 0.0031\n",
      "Epoch 334\n",
      "[334, 35]: Loss: 0.0028\n",
      "Epoch 335\n",
      "[335, 35]: Loss: 0.0051\n",
      "Epoch 336\n",
      "[336, 35]: Loss: 0.0023\n",
      "Epoch 337\n",
      "[337, 35]: Loss: 0.0028\n",
      "Epoch 338\n",
      "[338, 35]: Loss: 0.0028\n",
      "Epoch 339\n",
      "[339, 35]: Loss: 0.0036\n",
      "Epoch 340\n",
      "[340, 35]: Loss: 0.0065\n",
      "69 69\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.64      1.00      0.78         9\n",
      "       pasta       0.95      0.90      0.92        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.90        69\n",
      "   macro avg       0.89      0.91      0.89        69\n",
      "weighted avg       0.92      0.90      0.90        69\n",
      "\n",
      "Test Acc: 89.855%\n",
      "Epoch 341\n",
      "[341, 35]: Loss: 0.0045\n",
      "Epoch 342\n",
      "[342, 35]: Loss: 0.0064\n",
      "Epoch 343\n",
      "[343, 35]: Loss: 0.0031\n",
      "Epoch 344\n",
      "[344, 35]: Loss: 0.0033\n",
      "Epoch 345\n",
      "[345, 35]: Loss: 0.0044\n",
      "Epoch 346\n",
      "[346, 35]: Loss: 0.0045\n",
      "Epoch 347\n",
      "[347, 35]: Loss: 0.0050\n",
      "Epoch 348\n",
      "[348, 35]: Loss: 0.0079\n",
      "Epoch 349\n",
      "[349, 35]: Loss: 0.0025\n",
      "Epoch 350\n",
      "[350, 35]: Loss: 0.0051\n",
      "69 69\n",
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.64      1.00      0.78         9\n",
      "       pasta       0.95      0.90      0.92        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.90        69\n",
      "   macro avg       0.89      0.91      0.89        69\n",
      "weighted avg       0.92      0.90      0.90        69\n",
      "\n",
      "Test Acc: 89.855%\n",
      "Epoch 351\n",
      "[351, 35]: Loss: 0.0023\n",
      "Epoch 352\n",
      "[352, 35]: Loss: 0.0030\n",
      "Epoch 353\n",
      "[353, 35]: Loss: 0.0014\n",
      "Epoch 354\n",
      "[354, 35]: Loss: 0.0020\n",
      "Epoch 355\n",
      "[355, 35]: Loss: 0.0047\n",
      "Epoch 356\n",
      "[356, 35]: Loss: 0.0043\n",
      "Epoch 357\n",
      "[357, 35]: Loss: 0.0035\n",
      "Epoch 358\n",
      "[358, 35]: Loss: 0.0147\n",
      "Epoch 359\n",
      "[359, 35]: Loss: 0.0056\n",
      "Epoch 360\n",
      "[360, 35]: Loss: 0.0030\n",
      "69 69\n",
      "1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.69      1.00      0.82         9\n",
      "       pasta       0.95      0.95      0.95        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.91        69\n",
      "   macro avg       0.90      0.92      0.90        69\n",
      "weighted avg       0.93      0.91      0.92        69\n",
      "\n",
      "Test Acc: 91.304%\n",
      "Epoch 361\n",
      "[361, 35]: Loss: 0.0072\n",
      "Epoch 362\n",
      "[362, 35]: Loss: 0.0049\n",
      "Epoch 363\n",
      "[363, 35]: Loss: 0.0034\n",
      "Epoch 364\n",
      "[364, 35]: Loss: 0.0021\n",
      "Epoch 365\n",
      "[365, 35]: Loss: 0.0039\n",
      "Epoch 366\n",
      "[366, 35]: Loss: 0.0031\n",
      "Epoch 367\n",
      "[367, 35]: Loss: 0.0034\n",
      "Epoch 368\n",
      "[368, 35]: Loss: 0.0035\n",
      "Epoch 369\n",
      "[369, 35]: Loss: 0.0022\n",
      "Epoch 370\n",
      "[370, 35]: Loss: 0.0088\n",
      "69 69\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.64      1.00      0.78         9\n",
      "       pasta       0.95      0.90      0.92        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.90        69\n",
      "   macro avg       0.89      0.91      0.89        69\n",
      "weighted avg       0.92      0.90      0.90        69\n",
      "\n",
      "Test Acc: 89.855%\n",
      "Epoch 371\n",
      "[371, 35]: Loss: 0.0041\n",
      "Epoch 372\n",
      "[372, 35]: Loss: 0.0020\n",
      "Epoch 373\n",
      "[373, 35]: Loss: 0.0048\n",
      "Epoch 374\n",
      "[374, 35]: Loss: 0.0027\n",
      "Epoch 375\n",
      "[375, 35]: Loss: 0.0035\n",
      "Epoch 376\n",
      "[376, 35]: Loss: 0.0049\n",
      "Epoch 377\n",
      "[377, 35]: Loss: 0.0056\n",
      "Epoch 378\n",
      "[378, 35]: Loss: 0.0032\n",
      "Epoch 379\n",
      "[379, 35]: Loss: 0.0035\n",
      "Epoch 380\n",
      "[380, 35]: Loss: 0.0023\n",
      "69 69\n",
      "3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.64      1.00      0.78         9\n",
      "       pasta       0.95      0.90      0.92        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.90        69\n",
      "   macro avg       0.89      0.91      0.89        69\n",
      "weighted avg       0.92      0.90      0.90        69\n",
      "\n",
      "Test Acc: 89.855%\n",
      "Epoch 381\n",
      "[381, 35]: Loss: 0.0030\n",
      "Epoch 382\n",
      "[382, 35]: Loss: 0.0019\n",
      "Epoch 383\n",
      "[383, 35]: Loss: 0.0022\n",
      "Epoch 384\n",
      "[384, 35]: Loss: 0.0038\n",
      "Epoch 385\n",
      "[385, 35]: Loss: 0.0013\n",
      "Epoch 386\n",
      "[386, 35]: Loss: 0.0026\n",
      "Epoch 387\n",
      "[387, 35]: Loss: 0.0026\n",
      "Epoch 388\n",
      "[388, 35]: Loss: 0.0061\n",
      "Epoch 389\n",
      "[389, 35]: Loss: 0.0042\n",
      "Epoch 390\n",
      "[390, 35]: Loss: 0.0034\n",
      "69 69\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.69      1.00      0.82         9\n",
      "       pasta       0.95      0.95      0.95        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.91        69\n",
      "   macro avg       0.90      0.92      0.90        69\n",
      "weighted avg       0.93      0.91      0.92        69\n",
      "\n",
      "Test Acc: 91.304%\n",
      "Epoch 391\n",
      "[391, 35]: Loss: 0.0036\n",
      "Epoch 392\n",
      "[392, 35]: Loss: 0.0033\n",
      "Epoch 393\n",
      "[393, 35]: Loss: 0.0034\n",
      "Epoch 394\n",
      "[394, 35]: Loss: 0.0049\n",
      "Epoch 395\n",
      "[395, 35]: Loss: 0.0022\n",
      "Epoch 396\n",
      "[396, 35]: Loss: 0.0033\n",
      "Epoch 397\n",
      "[397, 35]: Loss: 0.0029\n",
      "Epoch 398\n",
      "[398, 35]: Loss: 0.0042\n",
      "Epoch 399\n",
      "[399, 35]: Loss: 0.0121\n",
      "Epoch 400\n",
      "[400, 35]: Loss: 0.0097\n",
      "69 69\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.64      1.00      0.78         9\n",
      "       pasta       1.00      0.90      0.95        20\n",
      "        rice       0.96      0.92      0.94        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.91        69\n",
      "   macro avg       0.90      0.92      0.90        69\n",
      "weighted avg       0.94      0.91      0.92        69\n",
      "\n",
      "Test Acc: 91.304%\n",
      "Epoch 401\n",
      "[401, 35]: Loss: 0.0023\n",
      "Epoch 402\n",
      "[402, 35]: Loss: 0.0115\n",
      "Epoch 403\n",
      "[403, 35]: Loss: 0.0046\n",
      "Epoch 404\n",
      "[404, 35]: Loss: 0.0076\n",
      "Epoch 405\n",
      "[405, 35]: Loss: 0.0022\n",
      "Epoch 406\n",
      "[406, 35]: Loss: 0.0019\n",
      "Epoch 407\n",
      "[407, 35]: Loss: 0.0040\n",
      "Epoch 408\n",
      "[408, 35]: Loss: 0.0017\n",
      "Epoch 409\n",
      "[409, 35]: Loss: 0.0024\n",
      "Epoch 410\n",
      "[410, 35]: Loss: 0.0039\n",
      "69 69\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.64      1.00      0.78         9\n",
      "       pasta       0.95      0.90      0.92        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.90        69\n",
      "   macro avg       0.89      0.91      0.89        69\n",
      "weighted avg       0.92      0.90      0.90        69\n",
      "\n",
      "Test Acc: 89.855%\n",
      "Epoch 411\n",
      "[411, 35]: Loss: 0.0053\n",
      "Epoch 412\n",
      "[412, 35]: Loss: 0.0019\n",
      "Epoch 413\n",
      "[413, 35]: Loss: 0.0023\n",
      "Epoch 414\n",
      "[414, 35]: Loss: 0.0029\n",
      "Epoch 415\n",
      "[415, 35]: Loss: 0.0036\n",
      "Epoch 416\n",
      "[416, 35]: Loss: 0.0032\n",
      "Epoch 417\n",
      "[417, 35]: Loss: 0.0026\n",
      "Epoch 418\n",
      "[418, 35]: Loss: 0.0045\n",
      "Epoch 419\n",
      "[419, 35]: Loss: 0.0018\n",
      "Epoch 420\n",
      "[420, 35]: Loss: 0.0023\n",
      "69 69\n",
      "1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.64      1.00      0.78         9\n",
      "       pasta       0.95      0.90      0.92        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.90        69\n",
      "   macro avg       0.89      0.91      0.89        69\n",
      "weighted avg       0.92      0.90      0.90        69\n",
      "\n",
      "Test Acc: 89.855%\n",
      "Epoch 421\n",
      "[421, 35]: Loss: 0.0025\n",
      "Epoch 422\n",
      "[422, 35]: Loss: 0.0038\n",
      "Epoch 423\n",
      "[423, 35]: Loss: 0.0031\n",
      "Epoch 424\n",
      "[424, 35]: Loss: 0.0026\n",
      "Epoch 425\n",
      "[425, 35]: Loss: 0.0029\n",
      "Epoch 426\n",
      "[426, 35]: Loss: 0.0019\n",
      "Epoch 427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[427, 35]: Loss: 0.0069\n",
      "Epoch 428\n",
      "[428, 35]: Loss: 0.0016\n",
      "Epoch 429\n",
      "[429, 35]: Loss: 0.0019\n",
      "Epoch 430\n",
      "[430, 35]: Loss: 0.0021\n",
      "69 69\n",
      "3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.64      1.00      0.78         9\n",
      "       pasta       0.95      0.90      0.92        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.90        69\n",
      "   macro avg       0.89      0.91      0.89        69\n",
      "weighted avg       0.92      0.90      0.90        69\n",
      "\n",
      "Test Acc: 89.855%\n",
      "Epoch 431\n",
      "[431, 35]: Loss: 0.0021\n",
      "Epoch 432\n",
      "[432, 35]: Loss: 0.0020\n",
      "Epoch 433\n",
      "[433, 35]: Loss: 0.0018\n",
      "Epoch 434\n",
      "[434, 35]: Loss: 0.0058\n",
      "Epoch 435\n",
      "[435, 35]: Loss: 0.0024\n",
      "Epoch 436\n",
      "[436, 35]: Loss: 0.0014\n",
      "Epoch 437\n",
      "[437, 35]: Loss: 0.0124\n",
      "Epoch 438\n",
      "[438, 35]: Loss: 0.0022\n",
      "Epoch 439\n",
      "[439, 35]: Loss: 0.0018\n",
      "Epoch 440\n",
      "[440, 35]: Loss: 0.0023\n",
      "69 69\n",
      "3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.64      1.00      0.78         9\n",
      "       pasta       0.95      0.90      0.92        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.90        69\n",
      "   macro avg       0.89      0.91      0.89        69\n",
      "weighted avg       0.92      0.90      0.90        69\n",
      "\n",
      "Test Acc: 89.855%\n",
      "Epoch 441\n",
      "[441, 35]: Loss: 0.0020\n",
      "Epoch 442\n",
      "[442, 35]: Loss: 0.0058\n",
      "Epoch 443\n",
      "[443, 35]: Loss: 0.0022\n",
      "Epoch 444\n",
      "[444, 35]: Loss: 0.0020\n",
      "Epoch 445\n",
      "[445, 35]: Loss: 0.0021\n",
      "Epoch 446\n",
      "[446, 35]: Loss: 0.0019\n",
      "Epoch 447\n",
      "[447, 35]: Loss: 0.0039\n",
      "Epoch 448\n",
      "[448, 35]: Loss: 0.0017\n",
      "Epoch 449\n",
      "[449, 35]: Loss: 0.0024\n",
      "Epoch 450\n",
      "[450, 35]: Loss: 0.0018\n",
      "69 69\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.64      1.00      0.78         9\n",
      "       pasta       0.95      0.90      0.92        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.90        69\n",
      "   macro avg       0.89      0.91      0.89        69\n",
      "weighted avg       0.92      0.90      0.90        69\n",
      "\n",
      "Test Acc: 89.855%\n",
      "Epoch 451\n",
      "[451, 35]: Loss: 0.0063\n",
      "Epoch 452\n",
      "[452, 35]: Loss: 0.0045\n",
      "Epoch 453\n",
      "[453, 35]: Loss: 0.0033\n",
      "Epoch 454\n",
      "[454, 35]: Loss: 0.0021\n",
      "Epoch 455\n",
      "[455, 35]: Loss: 0.0028\n",
      "Epoch 456\n",
      "[456, 35]: Loss: 0.0030\n",
      "Epoch 457\n",
      "[457, 35]: Loss: 0.0028\n",
      "Epoch 458\n",
      "[458, 35]: Loss: 0.0020\n",
      "Epoch 459\n",
      "[459, 35]: Loss: 0.0020\n",
      "Epoch 460\n",
      "[460, 35]: Loss: 0.0022\n",
      "69 69\n",
      "1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.64      1.00      0.78         9\n",
      "       pasta       0.95      0.90      0.92        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.90        69\n",
      "   macro avg       0.89      0.91      0.89        69\n",
      "weighted avg       0.92      0.90      0.90        69\n",
      "\n",
      "Test Acc: 89.855%\n",
      "Epoch 461\n",
      "[461, 35]: Loss: 0.0028\n",
      "Epoch 462\n",
      "[462, 35]: Loss: 0.0031\n",
      "Epoch 463\n",
      "[463, 35]: Loss: 0.0033\n",
      "Epoch 464\n",
      "[464, 35]: Loss: 0.0030\n",
      "Epoch 465\n",
      "[465, 35]: Loss: 0.0034\n",
      "Epoch 466\n",
      "[466, 35]: Loss: 0.0018\n",
      "Epoch 467\n",
      "[467, 35]: Loss: 0.0035\n",
      "Epoch 468\n",
      "[468, 35]: Loss: 0.0013\n",
      "Epoch 469\n",
      "[469, 35]: Loss: 0.0017\n",
      "Epoch 470\n",
      "[470, 35]: Loss: 0.0014\n",
      "69 69\n",
      "3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.64      1.00      0.78         9\n",
      "       pasta       0.95      0.90      0.92        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.90        69\n",
      "   macro avg       0.89      0.91      0.89        69\n",
      "weighted avg       0.92      0.90      0.90        69\n",
      "\n",
      "Test Acc: 89.855%\n",
      "Epoch 471\n",
      "[471, 35]: Loss: 0.0015\n",
      "Epoch 472\n",
      "[472, 35]: Loss: 0.0040\n",
      "Epoch 473\n",
      "[473, 35]: Loss: 0.0021\n",
      "Epoch 474\n",
      "[474, 35]: Loss: 0.0015\n",
      "Epoch 475\n",
      "[475, 35]: Loss: 0.0023\n",
      "Epoch 476\n",
      "[476, 35]: Loss: 0.0021\n",
      "Epoch 477\n",
      "[477, 35]: Loss: 0.0023\n",
      "Epoch 478\n",
      "[478, 35]: Loss: 0.0040\n",
      "Epoch 479\n",
      "[479, 35]: Loss: 0.0024\n",
      "Epoch 480\n",
      "[480, 35]: Loss: 0.0026\n",
      "69 69\n",
      "3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.69      1.00      0.82         9\n",
      "       pasta       0.95      0.95      0.95        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.91        69\n",
      "   macro avg       0.90      0.92      0.90        69\n",
      "weighted avg       0.93      0.91      0.92        69\n",
      "\n",
      "Test Acc: 91.304%\n",
      "Epoch 481\n",
      "[481, 35]: Loss: 0.0031\n",
      "Epoch 482\n",
      "[482, 35]: Loss: 0.0045\n",
      "Epoch 483\n",
      "[483, 35]: Loss: 0.0017\n",
      "Epoch 484\n",
      "[484, 35]: Loss: 0.0234\n",
      "Epoch 485\n",
      "[485, 35]: Loss: 0.0036\n",
      "Epoch 486\n",
      "[486, 35]: Loss: 0.0022\n",
      "Epoch 487\n",
      "[487, 35]: Loss: 0.0019\n",
      "Epoch 488\n",
      "[488, 35]: Loss: 0.0019\n",
      "Epoch 489\n",
      "[489, 35]: Loss: 0.0013\n",
      "Epoch 490\n",
      "[490, 35]: Loss: 0.0019\n",
      "69 69\n",
      "1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.64      1.00      0.78         9\n",
      "       pasta       0.95      0.90      0.92        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.90        69\n",
      "   macro avg       0.89      0.91      0.89        69\n",
      "weighted avg       0.92      0.90      0.90        69\n",
      "\n",
      "Test Acc: 89.855%\n",
      "Epoch 491\n",
      "[491, 35]: Loss: 0.0016\n",
      "Epoch 492\n",
      "[492, 35]: Loss: 0.0055\n",
      "Epoch 493\n",
      "[493, 35]: Loss: 0.0025\n",
      "Epoch 494\n",
      "[494, 35]: Loss: 0.0019\n",
      "Epoch 495\n",
      "[495, 35]: Loss: 0.0018\n",
      "Epoch 496\n",
      "[496, 35]: Loss: 0.0014\n",
      "Epoch 497\n",
      "[497, 35]: Loss: 0.0016\n",
      "Epoch 498\n",
      "[498, 35]: Loss: 0.0018\n",
      "Epoch 499\n",
      "[499, 35]: Loss: 0.0013\n",
      "Epoch 500\n",
      "[500, 35]: Loss: 0.0013\n",
      "69 69\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.64      1.00      0.78         9\n",
      "       pasta       0.95      0.90      0.92        20\n",
      "        rice       0.96      0.88      0.92        26\n",
      "       water       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.90        69\n",
      "   macro avg       0.89      0.91      0.89        69\n",
      "weighted avg       0.92      0.90      0.90        69\n",
      "\n",
      "Test Acc: 89.855%\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = list(fi_dict.keys())\n",
    "    \n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1,\n",
    "                               out_channels=16,\n",
    "                               kernel_size=(120, 40),\n",
    "                               stride=4)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=16,\n",
    "                               out_channels=8,\n",
    "                               kernel_size=(40, 1),\n",
    "                               stride=2)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(p=0.25)\n",
    "        self.dropout2 = nn.Dropout(p=0.25)\n",
    "        \n",
    "        self.linear1 = nn.Linear(8*154, 4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        o1 = F.relu(self.conv1(x))\n",
    "        o1 = self.dropout1(o1)\n",
    "        #print(o1.shape)\n",
    "        o2 = F.relu(self.conv2(o1))\n",
    "        o2 = self.dropout2(o2)\n",
    "        #print(o2.shape)\n",
    "        \n",
    "        out = self.linear1(o2.view(-1, 8*154))\n",
    "        \n",
    "        return out\n",
    "\n",
    "INTERVAL = 35\n",
    "    \n",
    "model = ConvNet()\n",
    "model.cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.00025, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(CLASS_WEIGHTS).cuda())\n",
    "\n",
    "for epoch in range(500):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    for i_batch, batch in enumerate(train_loader):\n",
    "        x, y = batch[0].cuda(), batch[1].cuda()\n",
    "        x = x.unsqueeze(1) # For conv net\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred_y = model(x)\n",
    "        \n",
    "        loss = criterion(pred_y, y)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i_batch % INTERVAL == INTERVAL-1:\n",
    "            running_loss += running_loss\n",
    "            print(f\"[{epoch+1}, {i_batch+1}]: Loss: {running_loss/INTERVAL:.4f}\")\n",
    "            \n",
    "    if epoch % 10 == 9:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for batch in test_loader:\n",
    "                x, y = batch[0].cuda(), batch[1].cuda()\n",
    "                x = x.unsqueeze(1)\n",
    "                \n",
    "                y_true += list(y.cpu().numpy())\n",
    "                \n",
    "                pred_y = model(x)\n",
    "                _, predicted = torch.max(pred_y.data, 1)\n",
    "                y_pred += list(predicted.cpu().numpy())\n",
    "                \n",
    "                total += y.size(0)\n",
    "                correct += (predicted == y).sum().item()\n",
    "                \n",
    "        print(len(y_true), len(y_pred))\n",
    "        print(y_true[0])\n",
    "        print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "                \n",
    "        acc = 100 * correct / total\n",
    "        print(f\"Test Acc: {acc:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <head>\n",
       "    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
       "    <title>Simple Test</title>\n",
       "    </head>\n",
       "    \n",
       "    <body>\n",
       "    <audio controls=\"controls\" style=\"width:600px\" >\n",
       "      <source src=\"files/Dataset/10/audio/0012_audio.wav\" type=\"audio/wav\" />\n",
       "      Your browser does not support the audio element.\n",
       "    </audio>\n",
       "    </body>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`pasta` with 99.9754250049591% confidence\n",
      "[[0. 1. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'Dataset/10/audio/0012_audio.wav'\n",
    "wavPlayer(path)\n",
    "\n",
    "#fi_dict = {'nothing': 0, 'pasta': 1, 'rice': 2, 'water': 3}\n",
    "rev = {0: 'nothing', 1: 'pasta', 2: 'rice', 3: 'water'}\n",
    "\n",
    "def getModelPrediction(model, path):\n",
    "    # Loading audio file and extracting MFCC feature\n",
    "    features = load_and_extract_mfcc(path)\n",
    "    \n",
    "    # Padding the sequence\n",
    "    pad_length = SEQUENCE_LENGTH - features.shape[0]\n",
    "    features = np.concatenate([features, np.zeros((pad_length, N_MFCC))])\n",
    "\n",
    "    feat_tensor = torch.Tensor(features)\n",
    "    feat_tensor = feat_tensor.unsqueeze(0)\n",
    "    feat_tensor = feat_tensor.unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        out = model(feat_tensor.cuda())\n",
    "        scores = F.softmax(out, dim=1).cpu().numpy()\n",
    "\n",
    "        _class = np.argmax(scores)\n",
    "        score = np.max(scores)\n",
    "\n",
    "        print(f\"`{rev[_class]}` with {score*100}% confidence\")\n",
    "\n",
    "        print(np.round(scores, 2))\n",
    "        \n",
    "    return _class\n",
    "getModelPrediction(model,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Dataset/10/audio/0000_audio.wav\n",
      "./Dataset/10/audio/0001_audio.wav\n",
      "./Dataset/10/audio/0002_audio.wav\n",
      "./Dataset/10/audio/0003_audio.wav\n",
      "./Dataset/10/audio/0004_audio.wav\n",
      "./Dataset/10/audio/0005_audio.wav\n",
      "./Dataset/10/audio/0006_audio.wav\n",
      "./Dataset/10/audio/0007_audio.wav\n",
      "./Dataset/10/audio/0008_audio.wav\n",
      "./Dataset/10/audio/0009_audio.wav\n",
      "./Dataset/10/audio/0010_audio.wav\n",
      "./Dataset/10/audio/0011_audio.wav\n",
      "./Dataset/10/audio/0012_audio.wav\n",
      "./Dataset/10/audio/0013_audio.wav\n",
      "./Dataset/10/audio/0014_audio.wav\n",
      "./Dataset/10/audio/0015_audio.wav\n",
      "./Dataset/10/audio/0016_audio.wav\n",
      "./Dataset/10/audio/0017_audio.wav\n",
      "./Dataset/10/audio/0018_audio.wav\n",
      "./Dataset/10/audio/0019_audio.wav\n",
      "./Dataset/10/audio/0020_audio.wav\n",
      "./Dataset/10/audio/0021_audio.wav\n",
      "./Dataset/10/audio/0022_audio.wav\n",
      "./Dataset/10/audio/0023_audio.wav\n",
      "./Dataset/10/audio/0024_audio.wav\n",
      "./Dataset/10/audio/0025_audio.wav\n",
      "./Dataset/10/audio/0026_audio.wav\n",
      "./Dataset/10/audio/0027_audio.wav\n",
      "./Dataset/10/audio/0028_audio.wav\n",
      "./Dataset/10/audio/0029_audio.wav\n",
      "./Dataset/10/audio/0030_audio.wav\n",
      "./Dataset/10/audio/0031_audio.wav\n",
      "./Dataset/10/audio/0032_audio.wav\n",
      "./Dataset/10/audio/0033_audio.wav\n",
      "./Dataset/10/audio/0034_audio.wav\n",
      "./Dataset/10/audio/0035_audio.wav\n",
      "./Dataset/10/audio/0036_audio.wav\n",
      "./Dataset/10/audio/0037_audio.wav\n",
      "./Dataset/10/audio/0038_audio.wav\n",
      "./Dataset/10/audio/0039_audio.wav\n",
      "./Dataset/10/audio/0040_audio.wav\n",
      "./Dataset/10/audio/0041_audio.wav\n",
      "./Dataset/10/audio/0042_audio.wav\n",
      "./Dataset/10/audio/0043_audio.wav\n",
      "./Dataset/10/audio/0044_audio.wav\n",
      "./Dataset/10/audio/0045_audio.wav\n",
      "./Dataset/10/audio/0046_audio.wav\n",
      "./Dataset/10/audio/0047_audio.wav\n",
      "./Dataset/10/audio/0048_audio.wav\n",
      "./Dataset/10/audio/0049_audio.wav\n",
      "./Dataset/10/audio/0050_audio.wav\n",
      "./Dataset/10/audio/0051_audio.wav\n",
      "./Dataset/10/audio/0052_audio.wav\n",
      "./Dataset/10/audio/0053_audio.wav\n",
      "./Dataset/10/audio/0054_audio.wav\n",
      "./Dataset/10/audio/0055_audio.wav\n",
      "./Dataset/10/audio/0056_audio.wav\n",
      "./Dataset/10/audio/0057_audio.wav\n",
      "./Dataset/10/audio/0058_audio.wav\n",
      "./Dataset/10/audio/0059_audio.wav\n",
      "./Dataset/10/audio/0060_audio.wav\n",
      "./Dataset/10/audio/0061_audio.wav\n",
      "./Dataset/10/audio/0062_audio.wav\n",
      "./Dataset/10/audio/0063_audio.wav\n",
      "./Dataset/10/audio/0064_audio.wav\n",
      "./Dataset/10/audio/0065_audio.wav\n",
      "./Dataset/10/audio/0066_audio.wav\n",
      "./Dataset/10/audio/0067_audio.wav\n",
      "./Dataset/10/audio/0068_audio.wav\n",
      "./Dataset/10/audio/0069_audio.wav\n",
      "./Dataset/10/audio/0070_audio.wav\n",
      "./Dataset/10/audio/0071_audio.wav\n",
      "./Dataset/10/audio/0072_audio.wav\n",
      "./Dataset/10/audio/0073_audio.wav\n",
      "./Dataset/10/audio/0074_audio.wav\n",
      "./Dataset/10/audio/0075_audio.wav\n",
      "./Dataset/10/audio/0076_audio.wav\n",
      "./Dataset/10/audio/0077_audio.wav\n",
      "./Dataset/10/audio/0078_audio.wav\n",
      "./Dataset/10/audio/0079_audio.wav\n",
      "./Dataset/10/audio/0080_audio.wav\n",
      "./Dataset/10/audio/0081_audio.wav\n",
      "./Dataset/10/audio/0082_audio.wav\n",
      "./Dataset/10/audio/0083_audio.wav\n",
      "#############\n",
      "`nothing` with 99.57925081253052% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`water` with 99.99998807907104% confidence\n",
      "[[0. 0. 0. 1.]]\n",
      "`water` with 99.52532052993774% confidence\n",
      "[[0. 0. 0. 1.]]\n",
      "`rice` with 95.76054215431213% confidence\n",
      "[[0.   0.04 0.96 0.  ]]\n",
      "`nothing` with 99.81774091720581% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`rice` with 99.00907278060913% confidence\n",
      "[[0.   0.   0.99 0.01]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 99.95726943016052% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`rice` with 44.145962595939636% confidence\n",
      "[[0.   0.25 0.44 0.31]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 95.21485567092896% confidence\n",
      "[[0.   0.95 0.05 0.  ]]\n",
      "`pasta` with 46.88379466533661% confidence\n",
      "[[0.07 0.47 0.46 0.  ]]\n",
      "`pasta` with 99.9754250049591% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`water` with 99.99958276748657% confidence\n",
      "[[0. 0. 0. 1.]]\n",
      "`water` with 95.45841813087463% confidence\n",
      "[[0.   0.   0.05 0.95]]\n",
      "`water` with 99.99990463256836% confidence\n",
      "[[0. 0. 0. 1.]]\n",
      "`nothing` with 99.96002316474915% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`water` with 99.99867677688599% confidence\n",
      "[[0. 0. 0. 1.]]\n",
      "`pasta` with 99.19071197509766% confidence\n",
      "[[0.   0.99 0.01 0.  ]]\n",
      "`water` with 99.74331259727478% confidence\n",
      "[[0. 0. 0. 1.]]\n",
      "`rice` with 99.37729239463806% confidence\n",
      "[[0.   0.   0.99 0.01]]\n",
      "`rice` with 96.86508178710938% confidence\n",
      "[[0.   0.03 0.97 0.  ]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`rice` with 99.96281862258911% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`nothing` with 98.98423552513123% confidence\n",
      "[[0.99 0.   0.   0.01]]\n",
      "`water` with 95.55448889732361% confidence\n",
      "[[0.   0.   0.04 0.96]]\n",
      "`pasta` with 99.95285272598267% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 99.99586343765259% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`rice` with 96.42183184623718% confidence\n",
      "[[0.   0.   0.96 0.04]]\n",
      "`rice` with 99.97522234916687% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`rice` with 99.94814991950989% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`rice` with 100.0% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`pasta` with 99.72545504570007% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`rice` with 100.0% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`water` with 89.75076079368591% confidence\n",
      "[[0.  0.  0.1 0.9]]\n",
      "`water` with 100.0% confidence\n",
      "[[0. 0. 0. 1.]]\n",
      "`rice` with 100.0% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`pasta` with 99.99785423278809% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`water` with 99.99725818634033% confidence\n",
      "[[0. 0. 0. 1.]]\n",
      "`water` with 99.99994039535522% confidence\n",
      "[[0. 0. 0. 1.]]\n",
      "`rice` with 100.0% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 98.31352233886719% confidence\n",
      "[[0.   0.98 0.02 0.  ]]\n",
      "`pasta` with 99.99542236328125% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`rice` with 99.99992847442627% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`water` with 99.98873472213745% confidence\n",
      "[[0. 0. 0. 1.]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`rice` with 97.94004559516907% confidence\n",
      "[[0.   0.02 0.98 0.  ]]\n",
      "`pasta` with 98.64229559898376% confidence\n",
      "[[0.   0.99 0.01 0.  ]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 99.99897480010986% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 99.72257018089294% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`rice` with 99.99998807907104% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`nothing` with 99.997878074646% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`nothing` with 99.84310269355774% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`nothing` with 99.95939135551453% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`nothing` with 99.99771118164062% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`rice` with 99.97991919517517% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`nothing` with 99.96744394302368% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`nothing` with 99.99693632125854% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 99.95042085647583% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`water` with 99.99994039535522% confidence\n",
      "[[0. 0. 0. 1.]]\n",
      "`pasta` with 64.938884973526% confidence\n",
      "[[0.   0.65 0.35 0.  ]]\n",
      "`pasta` with 99.99996423721313% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 85.39544343948364% confidence\n",
      "[[0.   0.85 0.15 0.  ]]\n",
      "`nothing` with 99.99140501022339% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`rice` with 98.26998710632324% confidence\n",
      "[[0.   0.02 0.98 0.  ]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`nothing` with 99.98626708984375% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "./Dataset/11/audio/0000_audio.wav\n",
      "./Dataset/11/audio/0001_audio.wav\n",
      "./Dataset/11/audio/0002_audio.wav\n",
      "./Dataset/11/audio/0003_audio.wav\n",
      "./Dataset/11/audio/0004_audio.wav\n",
      "./Dataset/11/audio/0005_audio.wav\n",
      "./Dataset/11/audio/0006_audio.wav\n",
      "./Dataset/11/audio/0007_audio.wav\n",
      "./Dataset/11/audio/0008_audio.wav\n",
      "./Dataset/11/audio/0009_audio.wav\n",
      "./Dataset/11/audio/0010_audio.wav\n",
      "./Dataset/11/audio/0011_audio.wav\n",
      "./Dataset/11/audio/0012_audio.wav\n",
      "./Dataset/11/audio/0013_audio.wav\n",
      "./Dataset/11/audio/0014_audio.wav\n",
      "./Dataset/11/audio/0015_audio.wav\n",
      "./Dataset/11/audio/0016_audio.wav\n",
      "./Dataset/11/audio/0017_audio.wav\n",
      "./Dataset/11/audio/0018_audio.wav\n",
      "./Dataset/11/audio/0019_audio.wav\n",
      "./Dataset/11/audio/0020_audio.wav\n",
      "./Dataset/11/audio/0021_audio.wav\n",
      "./Dataset/11/audio/0022_audio.wav\n",
      "./Dataset/11/audio/0023_audio.wav\n",
      "./Dataset/11/audio/0024_audio.wav\n",
      "./Dataset/11/audio/0025_audio.wav\n",
      "./Dataset/11/audio/0026_audio.wav\n",
      "./Dataset/11/audio/0027_audio.wav\n",
      "./Dataset/11/audio/0028_audio.wav\n",
      "./Dataset/11/audio/0029_audio.wav\n",
      "./Dataset/11/audio/0030_audio.wav\n",
      "./Dataset/11/audio/0031_audio.wav\n",
      "./Dataset/11/audio/0032_audio.wav\n",
      "./Dataset/11/audio/0033_audio.wav\n",
      "./Dataset/11/audio/0034_audio.wav\n",
      "./Dataset/11/audio/0035_audio.wav\n",
      "./Dataset/11/audio/0036_audio.wav\n",
      "./Dataset/11/audio/0037_audio.wav\n",
      "./Dataset/11/audio/0038_audio.wav\n",
      "./Dataset/11/audio/0039_audio.wav\n",
      "./Dataset/11/audio/0040_audio.wav\n",
      "./Dataset/11/audio/0041_audio.wav\n",
      "./Dataset/11/audio/0042_audio.wav\n",
      "./Dataset/11/audio/0043_audio.wav\n",
      "./Dataset/11/audio/0044_audio.wav\n",
      "./Dataset/11/audio/0045_audio.wav\n",
      "./Dataset/11/audio/0046_audio.wav\n",
      "./Dataset/11/audio/0047_audio.wav\n",
      "./Dataset/11/audio/0048_audio.wav\n",
      "./Dataset/11/audio/0049_audio.wav\n",
      "./Dataset/11/audio/0050_audio.wav\n",
      "./Dataset/11/audio/0051_audio.wav\n",
      "./Dataset/11/audio/0052_audio.wav\n",
      "./Dataset/11/audio/0053_audio.wav\n",
      "./Dataset/11/audio/0054_audio.wav\n",
      "./Dataset/11/audio/0055_audio.wav\n",
      "./Dataset/11/audio/0056_audio.wav\n",
      "./Dataset/11/audio/0057_audio.wav\n",
      "./Dataset/11/audio/0058_audio.wav\n",
      "./Dataset/11/audio/0059_audio.wav\n",
      "./Dataset/11/audio/0060_audio.wav\n",
      "./Dataset/11/audio/0061_audio.wav\n",
      "./Dataset/11/audio/0062_audio.wav\n",
      "./Dataset/11/audio/0063_audio.wav\n",
      "./Dataset/11/audio/0064_audio.wav\n",
      "./Dataset/11/audio/0065_audio.wav\n",
      "./Dataset/11/audio/0066_audio.wav\n",
      "./Dataset/11/audio/0067_audio.wav\n",
      "./Dataset/11/audio/0068_audio.wav\n",
      "./Dataset/11/audio/0069_audio.wav\n",
      "./Dataset/11/audio/0070_audio.wav\n",
      "./Dataset/11/audio/0071_audio.wav\n",
      "./Dataset/11/audio/0072_audio.wav\n",
      "./Dataset/11/audio/0073_audio.wav\n",
      "./Dataset/11/audio/0074_audio.wav\n",
      "./Dataset/11/audio/0075_audio.wav\n",
      "./Dataset/11/audio/0076_audio.wav\n",
      "./Dataset/11/audio/0077_audio.wav\n",
      "./Dataset/11/audio/0078_audio.wav\n",
      "./Dataset/11/audio/0079_audio.wav\n",
      "./Dataset/11/audio/0080_audio.wav\n",
      "./Dataset/11/audio/0081_audio.wav\n",
      "./Dataset/11/audio/0082_audio.wav\n",
      "./Dataset/11/audio/0083_audio.wav\n",
      "#############\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`rice` with 100.0% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`water` with 99.99868869781494% confidence\n",
      "[[0. 0. 0. 1.]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`rice` with 99.99990463256836% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`rice` with 99.95043277740479% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`nothing` with 99.99758005142212% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`water` with 100.0% confidence\n",
      "[[0. 0. 0. 1.]]\n",
      "`rice` with 99.99998807907104% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`pasta` with 84.4216525554657% confidence\n",
      "[[0.16 0.84 0.   0.  ]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`rice` with 99.9993085861206% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`nothing` with 98.73746037483215% confidence\n",
      "[[0.99 0.   0.   0.01]]\n",
      "`water` with 69.6721613407135% confidence\n",
      "[[0.29 0.01 0.   0.7 ]]\n",
      "`rice` with 58.58129858970642% confidence\n",
      "[[0.   0.41 0.59 0.  ]]\n",
      "`rice` with 95.43747901916504% confidence\n",
      "[[0.   0.05 0.95 0.  ]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`water` with 99.9940037727356% confidence\n",
      "[[0. 0. 0. 1.]]\n",
      "`nothing` with 99.99545812606812% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`nothing` with 99.9996542930603% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`rice` with 99.83232617378235% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`pasta` with 99.31308627128601% confidence\n",
      "[[0.   0.99 0.   0.  ]]\n",
      "`rice` with 99.9284565448761% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`rice` with 100.0% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`rice` with 78.60853672027588% confidence\n",
      "[[0.   0.   0.79 0.21]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`water` with 92.28525757789612% confidence\n",
      "[[0.08 0.   0.   0.92]]\n",
      "`water` with 84.51068997383118% confidence\n",
      "[[0.   0.   0.15 0.85]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`nothing` with 94.81402039527893% confidence\n",
      "[[0.95 0.   0.01 0.04]]\n",
      "`rice` with 99.99474287033081% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`water` with 99.99330043792725% confidence\n",
      "[[0. 0. 0. 1.]]\n",
      "`nothing` with 99.99722242355347% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`water` with 99.99991655349731% confidence\n",
      "[[0. 0. 0. 1.]]\n",
      "`water` with 86.80202960968018% confidence\n",
      "[[0.   0.   0.13 0.87]]\n",
      "`water` with 99.99352693557739% confidence\n",
      "[[0. 0. 0. 1.]]\n",
      "`nothing` with 99.90395903587341% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`nothing` with 99.83286261558533% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`nothing` with 99.98262524604797% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`pasta` with 99.91907477378845% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`water` with 99.99998807907104% confidence\n",
      "[[0. 0. 0. 1.]]\n",
      "`nothing` with 99.99061822891235% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`pasta` with 99.9976634979248% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 99.99998807907104% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`nothing` with 99.87277388572693% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`water` with 98.06028008460999% confidence\n",
      "[[0.   0.01 0.   0.98]]\n",
      "`rice` with 99.99731779098511% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`pasta` with 99.99998807907104% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`water` with 99.99998807907104% confidence\n",
      "[[0. 0. 0. 1.]]\n",
      "`water` with 99.99996423721313% confidence\n",
      "[[0. 0. 0. 1.]]\n",
      "`water` with 99.9987006187439% confidence\n",
      "[[0. 0. 0. 1.]]\n",
      "`pasta` with 99.99853372573853% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`rice` with 70.49183249473572% confidence\n",
      "[[0.   0.01 0.7  0.29]]\n",
      "`nothing` with 94.08000707626343% confidence\n",
      "[[0.94 0.06 0.   0.  ]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`nothing` with 99.87712502479553% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`water` with 96.15607857704163% confidence\n",
      "[[0.   0.   0.04 0.96]]\n",
      "`pasta` with 55.68905472755432% confidence\n",
      "[[0.   0.56 0.44 0.  ]]\n",
      "`water` with 99.9997615814209% confidence\n",
      "[[0. 0. 0. 1.]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`rice` with 75.70689916610718% confidence\n",
      "[[0.   0.23 0.76 0.01]]\n",
      "`nothing` with 99.99082088470459% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`water` with 99.99998807907104% confidence\n",
      "[[0. 0. 0. 1.]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`water` with 98.41228723526001% confidence\n",
      "[[0.   0.   0.02 0.98]]\n",
      "`water` with 98.8366425037384% confidence\n",
      "[[0.   0.   0.01 0.99]]\n",
      "`rice` with 99.99990463256836% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`rice` with 99.35078620910645% confidence\n",
      "[[0.   0.01 0.99 0.  ]]\n",
      "`pasta` with 99.99616146087646% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 99.99806880950928% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`water` with 100.0% confidence\n",
      "[[0. 0. 0. 1.]]\n",
      "`rice` with 99.73190426826477% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`water` with 99.13865327835083% confidence\n",
      "[[0.01 0.   0.   0.99]]\n",
      "`rice` with 100.0% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`nothing` with 98.35837483406067% confidence\n",
      "[[0.98 0.   0.   0.01]]\n",
      "`rice` with 100.0% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`rice` with 99.99809265136719% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`rice` with 100.0% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "./Dataset/12/audio/0000_audio.wav\n",
      "./Dataset/12/audio/0001_audio.wav\n",
      "./Dataset/12/audio/0002_audio.wav\n",
      "./Dataset/12/audio/0003_audio.wav\n",
      "./Dataset/12/audio/0004_audio.wav\n",
      "./Dataset/12/audio/0005_audio.wav\n",
      "./Dataset/12/audio/0006_audio.wav\n",
      "./Dataset/12/audio/0007_audio.wav\n",
      "./Dataset/12/audio/0008_audio.wav\n",
      "./Dataset/12/audio/0009_audio.wav\n",
      "./Dataset/12/audio/0010_audio.wav\n",
      "./Dataset/12/audio/0011_audio.wav\n",
      "./Dataset/12/audio/0012_audio.wav\n",
      "./Dataset/12/audio/0013_audio.wav\n",
      "./Dataset/12/audio/0014_audio.wav\n",
      "./Dataset/12/audio/0015_audio.wav\n",
      "./Dataset/12/audio/0016_audio.wav\n",
      "./Dataset/12/audio/0017_audio.wav\n",
      "./Dataset/12/audio/0018_audio.wav\n",
      "./Dataset/12/audio/0019_audio.wav\n",
      "./Dataset/12/audio/0020_audio.wav\n",
      "./Dataset/12/audio/0021_audio.wav\n",
      "./Dataset/12/audio/0022_audio.wav\n",
      "./Dataset/12/audio/0023_audio.wav\n",
      "./Dataset/12/audio/0024_audio.wav\n",
      "./Dataset/12/audio/0025_audio.wav\n",
      "./Dataset/12/audio/0026_audio.wav\n",
      "./Dataset/12/audio/0027_audio.wav\n",
      "./Dataset/12/audio/0028_audio.wav\n",
      "./Dataset/12/audio/0029_audio.wav\n",
      "./Dataset/12/audio/0030_audio.wav\n",
      "./Dataset/12/audio/0031_audio.wav\n",
      "./Dataset/12/audio/0032_audio.wav\n",
      "./Dataset/12/audio/0033_audio.wav\n",
      "./Dataset/12/audio/0034_audio.wav\n",
      "./Dataset/12/audio/0035_audio.wav\n",
      "./Dataset/12/audio/0036_audio.wav\n",
      "./Dataset/12/audio/0037_audio.wav\n",
      "./Dataset/12/audio/0038_audio.wav\n",
      "./Dataset/12/audio/0039_audio.wav\n",
      "./Dataset/12/audio/0040_audio.wav\n",
      "./Dataset/12/audio/0041_audio.wav\n",
      "./Dataset/12/audio/0042_audio.wav\n",
      "./Dataset/12/audio/0043_audio.wav\n",
      "./Dataset/12/audio/0044_audio.wav\n",
      "./Dataset/12/audio/0045_audio.wav\n",
      "./Dataset/12/audio/0046_audio.wav\n",
      "./Dataset/12/audio/0047_audio.wav\n",
      "./Dataset/12/audio/0048_audio.wav\n",
      "./Dataset/12/audio/0049_audio.wav\n",
      "./Dataset/12/audio/0050_audio.wav\n",
      "./Dataset/12/audio/0051_audio.wav\n",
      "./Dataset/12/audio/0052_audio.wav\n",
      "./Dataset/12/audio/0053_audio.wav\n",
      "./Dataset/12/audio/0054_audio.wav\n",
      "./Dataset/12/audio/0055_audio.wav\n",
      "./Dataset/12/audio/0056_audio.wav\n",
      "./Dataset/12/audio/0057_audio.wav\n",
      "./Dataset/12/audio/0058_audio.wav\n",
      "./Dataset/12/audio/0059_audio.wav\n",
      "#############\n",
      "`pasta` with 99.66191053390503% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`rice` with 87.44179606437683% confidence\n",
      "[[0.   0.13 0.87 0.  ]]\n",
      "`rice` with 99.36429262161255% confidence\n",
      "[[0.   0.01 0.99 0.  ]]\n",
      "`rice` with 83.7477445602417% confidence\n",
      "[[0.   0.16 0.84 0.  ]]\n",
      "`rice` with 98.6478865146637% confidence\n",
      "[[0.   0.01 0.99 0.  ]]\n",
      "`nothing` with 99.92200136184692% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`pasta` with 98.11210036277771% confidence\n",
      "[[0.   0.98 0.02 0.  ]]\n",
      "`rice` with 98.70443940162659% confidence\n",
      "[[0.   0.01 0.99 0.  ]]\n",
      "`nothing` with 99.86866116523743% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`rice` with 98.15176129341125% confidence\n",
      "[[0.   0.02 0.98 0.  ]]\n",
      "`nothing` with 99.99659061431885% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`pasta` with 99.99852180480957% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`nothing` with 99.98414516448975% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`pasta` with 99.99923706054688% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`rice` with 99.95935559272766% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`pasta` with 76.60776972770691% confidence\n",
      "[[0.   0.77 0.23 0.  ]]\n",
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`rice` with 99.99996423721313% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`rice` with 77.18580961227417% confidence\n",
      "[[0.07 0.16 0.77 0.  ]]\n",
      "`pasta` with 99.93554949760437% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 99.99809265136719% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 99.99998807907104% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 99.970942735672% confidence\n",
      "[[0. 1. 0. 0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`pasta` with 100.0% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 99.99995231628418% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`nothing` with 99.99574422836304% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`pasta` with 99.9990701675415% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 95.80512642860413% confidence\n",
      "[[0.   0.96 0.04 0.  ]]\n",
      "`nothing` with 87.62450218200684% confidence\n",
      "[[0.88 0.01 0.11 0.  ]]\n",
      "`pasta` with 99.78544116020203% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`nothing` with 99.99876022338867% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`pasta` with 99.99961853027344% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`rice` with 99.92291927337646% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`pasta` with 84.88975763320923% confidence\n",
      "[[0.   0.85 0.15 0.  ]]\n",
      "`rice` with 99.98819828033447% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`pasta` with 99.99666213989258% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`rice` with 85.91668009757996% confidence\n",
      "[[0.   0.14 0.86 0.  ]]\n",
      "`nothing` with 99.98041987419128% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`pasta` with 98.27314019203186% confidence\n",
      "[[0.   0.98 0.02 0.  ]]\n",
      "`rice` with 99.94786381721497% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`pasta` with 99.99276399612427% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`rice` with 99.64736104011536% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`pasta` with 99.82557892799377% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`nothing` with 99.9911904335022% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`pasta` with 99.79267120361328% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 99.99442100524902% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`rice` with 90.08485674858093% confidence\n",
      "[[0.  0.1 0.9 0. ]]\n",
      "`nothing` with 99.99971389770508% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`rice` with 99.86898303031921% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`rice` with 82.81264305114746% confidence\n",
      "[[0.   0.17 0.83 0.  ]]\n",
      "`nothing` with 99.22239780426025% confidence\n",
      "[[0.99 0.01 0.   0.  ]]\n",
      "`pasta` with 99.97331500053406% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 99.74144697189331% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`nothing` with 99.93139505386353% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`rice` with 99.99934434890747% confidence\n",
      "[[0. 0. 1. 0.]]\n",
      "`pasta` with 99.99758005142212% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`nothing` with 99.9830961227417% confidence\n",
      "[[1. 0. 0. 0.]]\n",
      "`pasta` with 75.60648918151855% confidence\n",
      "[[0.   0.76 0.24 0.  ]]\n",
      "`pasta` with 99.60346817970276% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "`pasta` with 99.85270500183105% confidence\n",
      "[[0. 1. 0. 0.]]\n",
      "228\n",
      "[0, 3, 3, 2, 0, 2, 1, 1, 2, 1, 1, 1, 1, 3, 3, 3, 0, 1, 3, 1, 3, 2, 2, 1, 2, 0, 3, 1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 1, 3, 3, 2, 1, 1, 3, 3, 2, 1, 1, 1, 1, 2, 3, 1, 2, 1, 1, 1, 1, 2, 0, 0, 0, 1, 0, 1, 1, 2, 0, 0, 1, 1, 3, 1, 1, 1, 0, 1, 1, 1, 2, 1, 0, 1, 1, 2, 1, 3, 1, 2, 2, 0, 3, 2, 1, 1, 2, 0, 3, 2, 2, 1, 3, 0, 0, 1, 1, 1, 2, 1, 2, 1, 2, 2, 1, 3, 3, 1, 0, 2, 3, 0, 3, 3, 3, 0, 0, 0, 1, 3, 0, 1, 1, 0, 3, 2, 1, 3, 3, 3, 1, 2, 0, 1, 0, 3, 1, 3, 1, 2, 0, 3, 1, 3, 3, 2, 2, 1, 1, 1, 3, 2, 3, 2, 0, 2, 2, 2, 1, 1, 2, 2, 2, 2, 0, 1, 2, 0, 2, 0, 1, 0, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 1, 2, 0, 1, 2, 1, 2, 1, 0, 1, 1, 2, 0, 2, 2, 0, 1, 1, 0, 2, 1, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from natsort import natsorted \n",
    "prediction_list = []\n",
    "for i in range(10,13,1):\n",
    "    path = './Dataset/'+str(i)+'/audio/*'\n",
    "    test_list = natsorted(glob.glob(path))\n",
    "    for tl in test_list:\n",
    "        print(tl)\n",
    "    print(\"#############\")\n",
    "    #print(test_list)\n",
    "    for i in range(0,len(test_list),1):\n",
    "        prediction_list.append(getModelPrediction(model,test_list[i]))\n",
    "print(len(prediction_list))        \n",
    "print(prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatesubmission(feature,data_list):\n",
    "    df = pd.read_csv('submissions/submissionfile.csv',index_col=0)\n",
    "    df[feature] = data_list\n",
    "    df.to_csv('./submissions/submissionfile-record.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatesubmission('Filling type',prediction_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
