{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from natsort import natsorted\n",
    "\n",
    "s_dict = {'table_start': 0, 'hand_start': 1, 'off_start': 2}\n",
    "fi_dict = {'nothing': 0, 'pasta': 1, 'rice': 2, 'water': 3}\n",
    "fu_dict = {'zero': 0, 'fifty': 1, 'ninety': 2}\n",
    "b_dict = {'regular': 0, 'textured': 1}\n",
    "l_dict = {'light0': 0, 'light1': 1}\n",
    "c_dict = {'c1': 1, 'c2': 2, 'c3': 3, 'c4': 4}\n",
    "obj_id_dict = {1: 'red cup', 2: 'small white cup',3:'small transparent cup',4:'green glass',5:'wine glass',\n",
    "              6:'champagne flute glass', 7:'cereal box',8:'biscuit box',9:'tea box'} \n",
    "\n",
    "valid_dict = {'s': list(s_dict.keys()), \n",
    "              'fi': list(fi_dict.keys()),\n",
    "              'fu': list(fu_dict.keys()),\n",
    "              'b': list(b_dict.keys()),\n",
    "              'l': list(l_dict.keys()),\n",
    "              'c': list(c_dict.keys()),\n",
    "              'obj_id': list(obj_id_dict.keys()),\n",
    "             }\n",
    "\n",
    "def retrieve_data(obj_id, s, fi, fu, b, l, c=[]):\n",
    "    if ((fi == 'nothing' and (fu =='fifty' or fu =='ninety')) or (fi == 'pasta' and fu == 'zero') or (fi == 'rice' and fu=='zero') or (fi=='water' and fu=='zero')): \n",
    "        #print('error')\n",
    "        return -1\n",
    "    for i in range(1,len(c),1):\n",
    "        if c[i] not in valid_dict['c']:\n",
    "            return -1\n",
    "    if  (obj_id not in obj_id_dict) or (s not in valid_dict['s']) or (fi not in valid_dict['fi']) or (fu not in valid_dict['fu']) or (b not in valid_dict['b']) or (l not in valid_dict['l']) :\n",
    "        return -1\n",
    "    \n",
    "    _obj_id = obj_id\n",
    "    _s_id = s_dict[s]\n",
    "    _fi_id = fi_dict[fi]\n",
    "    _fu_id = fu_dict[fu]\n",
    "    _b_id = b_dict[b]\n",
    "    _l_id = l_dict[l]\n",
    "    _c_id = []\n",
    "    \n",
    "    for i in range(0,len(c),1):\n",
    "        _c_id.append(c_dict[c[i]])\n",
    "    if(len(c)==0):\n",
    "        _c_id = [1,2,3,4]\n",
    "        \n",
    "    input_string = 's'+str(_s_id)+'_fi'+str(_fi_id)+'_fu'+str(_fu_id)+'_b'+str(_b_id)+'_l'+str(_l_id)\n",
    "    \n",
    "    audio_path = \"./*Dataset/\"+str(_obj_id)+\"/audio/\"+input_string+\"*\"\n",
    "    audio_list = glob.glob(audio_path)[0]\n",
    "    \n",
    "    calib_list = []\n",
    "    for i in range(0,len(_c_id),1):\n",
    "        calib_path = \"./*Dataset/\"+str(_obj_id)+\"/calib/\"+input_string+'_c'+str(_c_id[i])+'*'\n",
    "        calib_list.append(glob.glob(calib_path)[0])\n",
    "    \n",
    "    depth_list = []\n",
    "    for i in range(0,len(_c_id),1):\n",
    "        depth_path = \"./*Dataset/\"+str(_obj_id)+\"/depth/\"+input_string+'/c'+str(_c_id[i])+'/*'\n",
    "        depth_list.append(natsorted(glob.glob(depth_path), key=lambda y: y.lower()))\n",
    "        \n",
    "    imu_path = \"./*Dataset/\"+str(_obj_id)+\"/imu/\"+input_string+\"*\"\n",
    "    imu_list = tuple(glob.glob(imu_path))\n",
    "    \n",
    "    \n",
    "    ir_list=[]\n",
    "    for i in range(0,len(_c_id),1):\n",
    "        ir_path = \"./*Dataset/\"+str(_obj_id)+\"/ir/\"+input_string+'_c'+str(_c_id[i])+'*'\n",
    "        ir_list.append(glob.glob(ir_path))\n",
    "    \n",
    "    \n",
    "    rgb_list = []\n",
    "    for i in range(0,len(_c_id),1):\n",
    "        rgb_path = \"./*Dataset/\"+str(_obj_id)+\"/rgb/\"+input_string+'_c'+str(_c_id[i])+'*'\n",
    "        rgb_list.append(glob.glob(rgb_path)[0])\n",
    "    \n",
    "    \n",
    "    output_dict = {'audio': audio_list,'calib':calib_list,'depth':depth_list,'imu':imu_list,'ir':ir_list,'rgb':rgb_list}\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from object id: `1`\n",
      "Extracting data from object id: `2`\n",
      "Extracting data from object id: `3`\n",
      "Failed for ./Dataset/3/depth/s0_fi3_fu2_b0_l1/c3/0307.png\n",
      "Extracting data from object id: `4`\n",
      "Extracting data from object id: `5`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-9dfd42fb2c6d>:35: RuntimeWarning: invalid value encountered in true_divide\n",
      "  filter1_8u = ((filter1 / filter1.max()) * 255).astype(np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed for ./Dataset/5/depth/s2_fi1_fu1_b0_l0/c3/0206.png\n",
      "Failed for ./Dataset/5/depth/s2_fi1_fu2_b0_l0/c3/0335.png\n",
      "Extracting data from object id: `6`\n",
      "Extracting data from object id: `7`\n",
      "Failed for ./Dataset/7/depth/s2_fi0_fu0_b1_l0/c3/0098.png\n",
      "Failed for ./Dataset/7/depth/s2_fi1_fu1_b1_l0/c3/0100.png\n",
      "Failed for ./Dataset/7/depth/s2_fi1_fu2_b1_l0/c3/0105.png\n",
      "Failed for ./Dataset/7/depth/s2_fi2_fu1_b0_l0/c3/0139.png\n",
      "Extracting data from object id: `8`\n",
      "Failed for ./Dataset/8/depth/s2_fi1_fu1_b0_l0/c3/0140.png\n",
      "Failed for ./Dataset/8/depth/s2_fi1_fu2_b0_l0/c3/0143.png\n",
      "Failed for ./Dataset/8/depth/s2_fi2_fu1_b0_l0/c3/0134.png\n",
      "Extracting data from object id: `9`\n",
      "Failed for ./Dataset/9/depth/s2_fi1_fu1_b0_l0/c3/0132.png\n",
      "Failed for ./Dataset/9/depth/s2_fi2_fu2_b0_l0/c3/0131.png\n",
      "672 672\n",
      "Out of 684 samples, 12 failed to find object ROI\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def computeObjectBoundingBox(depth_img_path, debug=False):\n",
    "    # Define height limit to search, since bottom area is always a table\n",
    "    HEIGHT_LIMIT = 600\n",
    "    # Minimum area of the contours to be considered\n",
    "    MIN_CONTOUR_AREA = 15000\n",
    "    # In percentage (of bounding box)\n",
    "    BBOX_EXPANSION = 1.05\n",
    "\n",
    "    # Load image as uint16\n",
    "    cv_img = cv2.imread(depth_img_path, -1)[:HEIGHT_LIMIT]\n",
    "\n",
    "    if debug:\n",
    "        # Show image\n",
    "        plt.imshow(cv_img)\n",
    "        plt.title(\"Original Depth Image\")\n",
    "        plt.show()\n",
    "\n",
    "    # Find stats of image\n",
    "    #mean = np.mean(cv_img)\n",
    "    #std = np.std(cv_img)\n",
    "\n",
    "    # Define distance threshold\n",
    "    DIST_THRESHOLD = 700\n",
    "    #DIST_THRESHOLD = mean - std\n",
    "\n",
    "    # Filter pixels by distance threshold\n",
    "    filter1 = np.where(cv_img < DIST_THRESHOLD, cv_img, 0)\n",
    "\n",
    "    # Extract contours\n",
    "    # Convert to unsigned 8-bit\n",
    "    filter1_8u = ((filter1 / filter1.max()) * 255).astype(np.uint8)\n",
    "    # Apply closing operation, try to retrieve some of the \"missing\" regions\n",
    "    kernel = np.ones((15, 15), np.uint8)\n",
    "    filter1_8u = cv2.morphologyEx(filter1_8u, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    contours, _ = cv2.findContours(filter1_8u, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if len(contours) == 0:\n",
    "        if debug:\n",
    "            print(\"Couldn't find any contours\")\n",
    "            \n",
    "        return cv_img, None\n",
    "\n",
    "    if debug:\n",
    "        viz_img = np.dstack([filter1_8u.copy(), filter1_8u.copy(), filter1_8u.copy()])\n",
    "\n",
    "    # Iterate over contours, find the largest one\n",
    "    #candidates = []\n",
    "    bestContour = None\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > MIN_CONTOUR_AREA and bestContour is None:\n",
    "            bestContour = contour\n",
    "        elif area > MIN_CONTOUR_AREA and bestContour is not None:\n",
    "            # Use contour to find mask\n",
    "            curr_cnt_mask = np.zeros(cv_img.shape, np.uint8)\n",
    "            cv2.drawContours(curr_cnt_mask, [contour], 0, 255, -1)\n",
    "            \n",
    "            best_cnt_mask = np.zeros(cv_img.shape, np.uint8)\n",
    "            cv2.drawContours(best_cnt_mask, [bestContour], 0, 255, -1)\n",
    "            \n",
    "            best_cnt_mean = cv2.mean(cv_img, mask=best_cnt_mask)\n",
    "            curr_cnt_mean = cv2.mean(cv_img, mask=curr_cnt_mask)\n",
    "            \n",
    "            if curr_cnt_mean[0] < best_cnt_mean[0]:\n",
    "                bestContour = contour\n",
    "            \n",
    "            if debug:\n",
    "                plt.imshow(curr_cnt_mask, cmap='gray')\n",
    "                plt.title(\"Current contour mask\")\n",
    "                plt.show()\n",
    "                plt.imshow(best_cnt_mask, cmap='gray')\n",
    "                plt.title(\"best contour mask\")\n",
    "                plt.show()            \n",
    "\n",
    "    # Given the largest contour, find the bounding box\n",
    "    if bestContour is not None:\n",
    "        #print(\"Found object contour!\")\n",
    "\n",
    "        # If we found our object contour, find the bounding box\n",
    "        x, y , w, h = cv2.boundingRect(bestContour)\n",
    "\n",
    "    else:\n",
    "        if debug:\n",
    "            print(\"Couldn't determine object contour\")\n",
    "        return cv_img, None\n",
    "    \n",
    "    # Expand the bounding box a bit\n",
    "    inc_w_h = int((w * BBOX_EXPANSION - w) / 2)\n",
    "    inc_h_h = int((h * BBOX_EXPANSION - h) / 2)\n",
    "    \n",
    "    topx = x - inc_w_h\n",
    "    topy = y - inc_h_h\n",
    "    botx = x + w + inc_w_h\n",
    "    boty = y + h + inc_h_h\n",
    "    \n",
    "    # Make sure values stay within range\n",
    "    if topx < 0:\n",
    "        topx = 0\n",
    "    if topy < 0:\n",
    "        topy = 0\n",
    "    if botx > cv_img.shape[1]:\n",
    "        botx = cv_img.shape[1]\n",
    "    if boty > cv_img.shape[0]:\n",
    "        boty = cv_img.shape[0]\n",
    "    \n",
    "    pt1 = (topx, topy)\n",
    "    pt2 = (botx, boty)\n",
    "\n",
    "    if debug:\n",
    "        cv2.rectangle(viz_img, pt1, pt2, (255, 0, 0), 3)    \n",
    "\n",
    "        cv2.drawContours(viz_img, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "        plt.imshow(filter1)\n",
    "        plt.title(f\"Cropped to `DIST_THRESHOLD={DIST_THRESHOLD}` pixels\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(filter1_8u, cmap='gray')\n",
    "        plt.title(f\"Unsigned 8 image\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(viz_img, cmap='gray')\n",
    "        plt.title(f\"Viz image\")\n",
    "        plt.show()\n",
    "\n",
    "    return cv_img, (filter1, pt1, pt2)\n",
    "    \n",
    "def findBestFrameROI(depth_imgs, search_max=30):\n",
    "    _index = -1\n",
    "    if len(depth_imgs) < search_max:\n",
    "        search_n = len(depth_imgs) - 1\n",
    "    else:\n",
    "        search_n = search_max\n",
    "        \n",
    "    for _ in range(search_n):\n",
    "        depth_img, ret = computeObjectBoundingBox(depth_imgs[_index], debug=False)\n",
    "        \n",
    "        #plt.imshow(depth_img)\n",
    "        #plt.show()\n",
    "        \n",
    "        if ret != None:\n",
    "            filter1, (topx, topy), (botx, boty) = ret\n",
    "\n",
    "            roi = filter1[topy:boty, topx:botx]\n",
    "            \n",
    "            return roi\n",
    "\n",
    "            #plt.imshow(filter1)\n",
    "            #plt.show()\n",
    "\n",
    "            #plt.imshow(roi)\n",
    "            #plt.show()\n",
    "            #print('#'*80)\n",
    "\n",
    "        _index += -1\n",
    "        \n",
    "    #print(\"No roi for this sample.\")\n",
    "    return None\n",
    "                     \n",
    "# The capacity of the containers in mL\n",
    "ANNOTATION = {1: 520.0, # Red cup\n",
    "              2: 185.0, # Small white cup\n",
    "              3: 202.0, # Small transparent cup\n",
    "              4: 296.0, # Green glass\n",
    "              5: 363.0, # Wine glass\n",
    "              6: 128.0, # Champagne flute\n",
    "              7: 3209.397, # Cereal box\n",
    "              8: 1239.84, # Biscuits box\n",
    "              9: 471.6} # Tea box\n",
    "\n",
    "ANNOTATION_MEAN = 734.981888888889\n",
    "ANNOTATION_STD = 929.7103190574344\n",
    "\n",
    "IMG_WIDTH = 1280\n",
    "IMG_HEIGHT = 720\n",
    "MAX_VAL = 700 # Anything larger than this distance in the images, is discarded\n",
    "\n",
    "total = 0\n",
    "failed = 0\n",
    "failed_samples = []\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "for obj_id in range(1, 10):\n",
    "    print(f\"Extracting data from object id: `{obj_id}`\")\n",
    "    for sit in s_dict.keys():\n",
    "        for fi in fi_dict.keys():\n",
    "            for fu in fu_dict.keys():\n",
    "                for b in b_dict.keys():\n",
    "                    for l in l_dict.keys():\n",
    "                        try:\n",
    "                            sample = retrieve_data(obj_id, s=sit, fi=fi, fu=fu, b=b, l=l)\n",
    "                        except Exception as e:\n",
    "                            #print(f\"Failed...: {(obj_id, sit, fi, fu, b, l)}\")\n",
    "                            pass\n",
    "                        if sample != -1:\n",
    "                            ret = findBestFrameROI(sample['depth'][2])\n",
    "                            total += 1\n",
    "                            if ret is None:\n",
    "                                print(f\"Failed for {sample['depth'][2][-1]}\")\n",
    "                                failed += 1\n",
    "                                failed_samples.append((sit, fi, fu, b, l))\n",
    "                            else:\n",
    "                                # Add sample to dataset\n",
    "                                roi_h, roi_w = ret.shape\n",
    "                                \n",
    "                                # Normalize ROI by max val\n",
    "                                data.append((np.divide(ret, MAX_VAL), roi_h/IMG_HEIGHT, roi_w/IMG_WIDTH))\n",
    "\n",
    "                                # Get label data\n",
    "                                labels.append(ANNOTATION[obj_id]/4000)\n",
    "\n",
    "print(len(data), len(labels))\n",
    "print(f\"Out of {total} samples, {failed} failed to find object ROI\")          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.032      0.04625    0.0505     0.074      0.09075    0.1179\n",
      " 0.13       0.30996    0.80234925] [84 84 83 84 82 58 84 57 56]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.032      0.04625    0.0505     0.074      0.09075    0.1179\n",
      " 0.13       0.30996    0.80234925] [77 72 76 72 70 50 66 44 44]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.032      0.04625    0.0505     0.074      0.09075    0.1179\n",
      " 0.13       0.30996    0.80234925] [ 7 12  7 12 12  8 18 13 12]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUpElEQVR4nO3de7SldX3f8ffHAZYXJoLOEbnJmISQoA2ETvFCQiBeyowsMVk0QowaQ9aIhVbbtA2R1cR2LVM1K60x42JClIBRwbSKpTIKxCZBl6CeoQMOQWQgWMaZMoeLDAgrOvDtH/uZZHPc5zJ773OZX96vtc7az+X3/H7ffeY8n3nOb+/9nFQVkqR2PWOpC5AkLSyDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9NIsk9yZ59VLXIY3CoNeyleSxvq+nkjzRt/6mIfr7qyS/sRC1dv1Xkh9fqP4Xexy144ClLkCaSVUdvHc5yb3Ab1TVXyxdRdL+ySt67XeSPCPJRUnuTvJgkj9P8rxu3zOTfLzb/t0kX09yWJL3Aj8HbOh+I9gwQ99vTvLt7viLp+07OclNXb87k2xIclC378au2a1d/29McmiSzyWZSvJwt3xUX3+/luSeJI8m+dv+31KS/HqSO7rjrktyzEzjjOv7qnYZ9Nof/WvgDcDPA0cADwMf7va9FXgucDTwfOB84Imquhj4EnBhVR1cVRdO7zTJ8cAlwJu7fp8PHNXX5Eng3wCrgFcArwL+JUBVndq1OaHr/1P0zq8/BY4BXgQ8AWzoxnoO8CFgbVWtBF4JbOn2vQF4N/BLwERX95WzjCPNyqDX/ujtwMVVtb2q/g54D3B2kgOAH9AL6B+vqieranNV7Z5nv2cDn6uqG7t+/yPw1N6dXV83V9WeqroX+GN6/9kMVFUPVtWnq+rxqnoUeO+09k8BL03yrKraWVW39z2//1JVd1TVHuD3gBP3XtVL+8qg1/7oGODqbgrlu8Ad9K62DwP+DLgOuCrJjiQfSHLgPPs9Arhv70pVfQ94cO96kp/opl/+X5Ld9AJ41UydJXl2kj/upoJ2AzcChyRZ0fX9Rnq/cexMcm2Sn+x7fn/Y9/weAgIcOc/nIT2NQa/90X30pjwO6ft6ZlV9p6p+UFX/qaqOpzcdcibwlu64uW7VupPelA/QC2p6vx3sdQnwTeDYqvoRetMrmaW/3wSOA17Wtd877RKAqrquql4DHN71+yd9z+/t057fs6rqK3PULw1k0Gt/tBF4b98LlBNJzuqWT0/yT5KsAHbTm8p5sjvufuBHZ+n3fwBnJvnZ7kXW/8zTz5GVXZ+PdVff75h2/PT+V9Kbl/9u92Lx7+7d0b1A/Ppurv7vgMf66twI/HaSl3Rtn5vkX8wyjjQrg177oz8ErgGuT/IocDPwsm7fC+kF9m56Uzp/DXy877izu3eyfGh6p90c+QXAJ+ld3T8MbO9r8u+AXwEepXf1Pf2F0PcAV3RTLr8MfBB4FvBAV+MX+to+g94V/w56UzM/zz+8sHs18H5600+7ga3A2lnGkWYV//CIJLXNK3pJapxBL0mNM+glqXEGvSQ1blne1GzVqlW1evXqpS5DkvYbmzdvfqCqJgbtW5ZBv3r1aiYnJ5e6DEnabyT59kz7nLqRpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGLctPxi4Xqy+6dqlL0D8S977vdUtdghrmFb0kNW7OK/okl9H7A8u7quql3bZP0fujxwCHAN+tqhMHHHsvvT+79iSwp6rWjKluSdI8zWfq5nJgA/CxvRuq6o17l5P8AfDILMefXlUPDFugJGk0cwZ9Vd2YZPWgfUkC/DLwC+MtS5I0LqPO0f8ccH9V3TXD/gKuT7I5yfrZOkqyPslkksmpqakRy5Ik7TVq0J8LXDnL/lOq6iRgLXBBklNnalhVl1bVmqpaMzEx8N75kqQhDB30SQ4Afgn41ExtqmpH97gLuBo4edjxJEnDGeWK/tXAN6tq+6CdSZ6TZOXeZeC1wNYRxpMkDWHOoE9yJXATcFyS7UnO63adw7RpmyRHJNnUrR4GfDnJrcDXgGur6gvjK12SNB/zedfNuTNs/7UB23YA67rle4ATRqxPkjQiPxkrSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGzRn0SS5LsivJ1r5t70nynSRbuq91Mxx7RpI7k2xLctE4C5ckzc98rugvB84YsP2/VdWJ3dem6TuTrAA+DKwFjgfOTXL8KMVKkvbdnEFfVTcCDw3R98nAtqq6p6q+D1wFnDVEP5KkEYwyR39hktu6qZ1DB+w/Erivb317t22gJOuTTCaZnJqaGqEsSVK/YYP+EuDHgBOBncAfDGiTAdtqpg6r6tKqWlNVayYmJoYsS5I03VBBX1X3V9WTVfUU8Cf0pmmm2w4c3bd+FLBjmPEkScMbKuiTHN63+ovA1gHNvg4cm+TFSQ4CzgGuGWY8SdLwDpirQZIrgdOAVUm2A78LnJbkRHpTMfcCb+/aHgF8pKrWVdWeJBcC1wErgMuq6vYFeRaSpBnNGfRVde6AzR+doe0OYF3f+ibgh956KUlaPH4yVpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekho351+YkrTwVl907VKX8Pfufd/rlroEjZlX9JLUOINekho3Z9AnuSzJriRb+7b9fpJvJrktydVJDpnh2HuTfCPJliST4yxckjQ/87mivxw4Y9q2G4CXVtVPA98CfnuW40+vqhOras1wJUqSRjFn0FfVjcBD07ZdX1V7utWbgaMWoDZJ0hiMY47+14HPz7CvgOuTbE6yfrZOkqxPMplkcmpqagxlSZJgxKBPcjGwB/jEDE1OqaqTgLXABUlOnamvqrq0qtZU1ZqJiYlRypIk9Rk66JO8FTgTeFNV1aA2VbWje9wFXA2cPOx4kqThDBX0Sc4Afgt4fVU9PkOb5yRZuXcZeC2wdVBbSdLCmc/bK68EbgKOS7I9yXnABmAlcEP31smNXdsjkmzqDj0M+HKSW4GvAddW1RcW5FlIkmY05y0QqurcAZs/OkPbHcC6bvke4ISRqpMkjazpe90sp/uHSPsLz5uls1D3GfIWCJLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1Lj5gz6JJcl2ZVka9+25yW5Icld3eOhMxx7RpI7k2xLctE4C5ckzc98rugvB86Ytu0i4ItVdSzwxW79aZKsAD4MrAWOB85NcvxI1UqS9tmcQV9VNwIPTdt8FnBFt3wF8IYBh54MbKuqe6rq+8BV3XGSpEU07Bz9YVW1E6B7fMGANkcC9/Wtb++2DZRkfZLJJJNTU1NDliVJmm4hX4zNgG01U+OqurSq1lTVmomJiQUsS5L+cRk26O9PcjhA97hrQJvtwNF960cBO4YcT5I0pGGD/hrgrd3yW4H/OaDN14Fjk7w4yUHAOd1xkqRFNJ+3V14J3AQcl2R7kvOA9wGvSXIX8JpunSRHJNkEUFV7gAuB64A7gD+vqtsX5mlIkmZywFwNqurcGXa9akDbHcC6vvVNwKahq5MkjcxPxkpS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNGzrokxyXZEvf1+4k75rW5rQkj/S1+Z3RS5Yk7Ys5/zj4TKrqTuBEgCQrgO8AVw9o+qWqOnPYcSRJoxnX1M2rgLur6ttj6k+SNCbjCvpzgCtn2PeKJLcm+XySl4xpPEnSPI0c9EkOAl4P/PcBu28BjqmqE4A/Aj47Sz/rk0wmmZyamhq1LElSZxxX9GuBW6rq/uk7qmp3VT3WLW8CDkyyalAnVXVpVa2pqjUTExNjKEuSBOMJ+nOZYdomyQuTpFs+uRvvwTGMKUmap6HfdQOQ5NnAa4C39207H6CqNgJnA+9Isgd4AjinqmqUMSVJ+2akoK+qx4HnT9u2sW95A7BhlDEkSaMZKeiXo9UXXbvUJUjSsuItECSpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGjRT0Se5N8o0kW5JMDtifJB9Ksi3JbUlOGmU8SdK+G8cfBz+9qh6YYd9a4Nju62XAJd2jJGmRLPTUzVnAx6rnZuCQJIcv8JiSpD6jBn0B1yfZnGT9gP1HAvf1rW/vtv2QJOuTTCaZnJqaGrEsSdJeowb9KVV1Er0pmguSnDptfwYcU4M6qqpLq2pNVa2ZmJgYsSxJ0l4jBX1V7egedwFXAydPa7IdOLpv/ShgxyhjSpL2zdBBn+Q5SVbuXQZeC2yd1uwa4C3du29eDjxSVTuHrlaStM9GedfNYcDVSfb288mq+kKS8wGqaiOwCVgHbAMeB942WrmSpH01dNBX1T3ACQO2b+xbLuCCYceQJI3OT8ZKUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxQwd9kqOT/GWSO5LcnuSdA9qcluSRJFu6r98ZrVxJ0r46YIRj9wC/WVW3JFkJbE5yQ1X9zbR2X6qqM0cYR5I0gqGv6KtqZ1Xd0i0/CtwBHDmuwiRJ4zGWOfokq4GfAb46YPcrktya5PNJXjJLH+uTTCaZnJqaGkdZkiTGEPRJDgY+DbyrqnZP230LcExVnQD8EfDZmfqpqkurak1VrZmYmBi1LElSZ6SgT3IgvZD/RFV9Zvr+qtpdVY91y5uAA5OsGmVMSdK+GeVdNwE+CtxRVf91hjYv7NqR5ORuvAeHHVOStO9GedfNKcCbgW8k2dJtezfwIoCq2gicDbwjyR7gCeCcqqoRxpQk7aOhg76qvgxkjjYbgA3DjiFJGp2fjJWkxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuNGCvokZyS5M8m2JBcN2J8kH+r235bkpFHGkyTtu6GDPskK4MPAWuB44Nwkx09rthY4tvtaD1wy7HiSpOGMckV/MrCtqu6pqu8DVwFnTWtzFvCx6rkZOCTJ4SOMKUnaRweMcOyRwH1969uBl82jzZHAzumdJVlP76of4LEkd84x/irggX0peJEs17rA2oa1XGtbrnWBtQ0l7x+ptmNm2jFK0GfAthqiTW9j1aXApfMePJmsqjXzbb9YlmtdYG3DWq61Lde6wNqGtVC1jTJ1sx04um/9KGDHEG0kSQtolKD/OnBskhcnOQg4B7hmWptrgLd07755OfBIVf3QtI0kaeEMPXVTVXuSXAhcB6wALquq25Oc3+3fCGwC1gHbgMeBt41e8t+b9zTPIluudYG1DWu51rZc6wJrG9aC1JaqgVPmkqRG+MlYSWqcQS9Jjdtvgj7J85LckOSu7vHQWdquSPJ/knxuOdSV5Ogkf5nkjiS3J3nnAte0bG9NMY/a3tTVdFuSryQ5YTnU1dfunyV5MsnZi1HXfGtLclqSLd3P118vl9qSPDfJ/0pya1fbOF+nm62uy5LsSrJ1hv1LeQ7MVdv4z4Gq2i++gA8AF3XLFwHvn6XtvwU+CXxuOdQFHA6c1C2vBL4FHL9A9awA7gZ+FDgIuHX6WPReIP88vc85vBz46iL9G86ntlcCh3bLaxejtvnU1dfuf9N7k8HZy+h7dgjwN8CLuvUXLKPa3r33nAAmgIeAgxahtlOBk4CtM+xfknNgnrWN/RzYb67o6d1O4Ypu+QrgDYMaJTkKeB3wkeVSV1XtrKpbuuVHgTvofUJ4ISznW1PMWVtVfaWqHu5Wb6b32Yslr6vzr4BPA7sWoaZ9qe1XgM9U1f8FqKrFqm8+tRWwMkmAg+kF/Z6FLqyqbuzGmsmS3Z5lrtoW4hzYn4L+sOreg989vmCGdh8E/gPw1DKrC4Akq4GfAb66QPXMdNuJfW2zEPZ13PPoXXUttDnrSnIk8IvAxkWop998vmc/ARya5K+SbE7ylmVU2wbgp+h9UPIbwDurarHOzdks1Tmwr8ZyDoxyC4SxS/IXwAsH7Lp4nsefCeyqqs1JTlsudfX1czC9K8J3VdXucdQ2aJgB24a+NcWYzXvcJKfT+yH/2QWtqBtuwLbpdX0Q+K2qerJ3cbpo5lPbAcA/BV4FPAu4KcnNVfWtZVDbPwe2AL8A/BhwQ5IvLeDP/3wt1Tkwb+M8B5ZV0FfVq2fal+T+JIdX1c7uV6xBv56eArw+yTrgmcCPJPl4Vf3qEtdFkgPphfwnquozo9Qzh+V8a4p5jZvkp+lNva2tqgeXSV1rgKu6kF8FrEuyp6o+uwxq2w48UFXfA76X5EbgBHqvBS11bW8D3le9CedtSf4W+Engawtc21yW9e1Zxn4OLNYLEGN4AeP3efqLnh+Yo/1pLM6LsXPWRe/q4WPABxehngOAe4AX8w8vkL1kWpvX8fQXor62SP+G86ntRfQ+Sf3KRfzZmrOuae0vZ/FejJ3P9+yngC92bZ8NbAVeukxquwR4T7d8GPAdYNUife9WM/MLnktyDsyztrGfA4v2xMbwjXl+98N8V/f4vG77EcCmAe0XK+jnrIver14F3Ebv19gtwLoFrGkdvau5u4GLu23nA+d3y6H3R2PupjdvumYR/x3nqu0jwMN936fJ5VDXtLaLFvTzrQ349/TeebOV3tTgsqitOw+u737OtgK/ukh1XUnvdug/oHf1ft4yOgfmqm3s54C3QJCkxu1P77qRJA3BoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mN+//QlKkJB2oWZwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Resize\n",
    "import torch\n",
    "\n",
    "NET_SIZE = (112, 112)\n",
    "\n",
    "# Analyze class distribution and \n",
    "_classes, counts = np.unique(labels, return_counts=True)\n",
    "print(_classes, counts)\n",
    "plt.bar(_classes, counts)\n",
    "plt.title(\"Whole dataset\")\n",
    "plt.show()\n",
    "\n",
    "# Split in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels,\n",
    "                                                   test_size=0.15)\n",
    "\n",
    "_classes, counts = np.unique(y_train, return_counts=True)\n",
    "n_train_samples = len(y_train)\n",
    "print(_classes, counts)\n",
    "plt.bar(_classes, counts)\n",
    "plt.title(\"Train dataset\")\n",
    "plt.show()\n",
    "\n",
    "_classes, counts = np.unique(y_test, return_counts=True)\n",
    "print(_classes, counts)\n",
    "plt.bar(_classes, counts)\n",
    "plt.title(\"Test dataset\")\n",
    "plt.show()\n",
    "\n",
    "class VolumeDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.images = []\n",
    "        self.rois_size = []\n",
    "        \n",
    "        for _x in x:\n",
    "            self.images.append(cv2.resize(_x[0], (112, 112)))\n",
    "            self.rois_size.append((_x[1], _x[2]))\n",
    "        \n",
    "        self.y_volume = y\n",
    "        \n",
    "        assert len(self.images) == len(self.rois_size)\n",
    "        assert len(self.images) == len(self.y_volume)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (torch.Tensor(self.images[idx]).unsqueeze(0), torch.Tensor(self.rois_size[idx])), torch.Tensor([self.y_volume[idx]])\n",
    "    \n",
    "train_dataset = VolumeDataset(X_train, y_train)\n",
    "test_dataset = VolumeDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True,\n",
    "                          num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False,\n",
    "                          num_workers=0)\n",
    "\n",
    "#for (img, roi_info), volume in test_loader:\n",
    "#    print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "[1, 15]: MSE Loss: 0.2125\n",
      "[1, 30]: MSE Loss: 0.1393\n",
      "[1, 45]: MSE Loss: 0.0915\n",
      "[1, 60]: MSE Loss: 0.0770\n",
      "Epoch 2\n",
      "[2, 15]: MSE Loss: 0.0627\n",
      "[2, 30]: MSE Loss: 0.0664\n",
      "[2, 45]: MSE Loss: 0.0704\n",
      "[2, 60]: MSE Loss: 0.0658\n",
      "Epoch 3\n",
      "[3, 15]: MSE Loss: 0.0513\n",
      "[3, 30]: MSE Loss: 0.0551\n",
      "[3, 45]: MSE Loss: 0.0577\n",
      "[3, 60]: MSE Loss: 0.0709\n",
      "Epoch 4\n",
      "[4, 15]: MSE Loss: 0.0686\n",
      "[4, 30]: MSE Loss: 0.0375\n",
      "[4, 45]: MSE Loss: 0.0431\n",
      "[4, 60]: MSE Loss: 0.0581\n",
      "Epoch 5\n",
      "[5, 15]: MSE Loss: 0.0282\n",
      "[5, 30]: MSE Loss: 0.0434\n",
      "[5, 45]: MSE Loss: 0.0394\n",
      "[5, 60]: MSE Loss: 0.0292\n",
      "Epoch 6\n",
      "[6, 15]: MSE Loss: 0.0287\n",
      "[6, 30]: MSE Loss: 0.0243\n",
      "[6, 45]: MSE Loss: 0.0304\n",
      "[6, 60]: MSE Loss: 0.0187\n",
      "Epoch 7\n",
      "[7, 15]: MSE Loss: 0.0164\n",
      "[7, 30]: MSE Loss: 0.0197\n",
      "[7, 45]: MSE Loss: 0.0211\n",
      "[7, 60]: MSE Loss: 0.0280\n",
      "Epoch 8\n",
      "[8, 15]: MSE Loss: 0.0265\n",
      "[8, 30]: MSE Loss: 0.0202\n",
      "[8, 45]: MSE Loss: 0.0316\n",
      "[8, 60]: MSE Loss: 0.0232\n",
      "Epoch 9\n",
      "[9, 15]: MSE Loss: 0.0163\n",
      "[9, 30]: MSE Loss: 0.0145\n",
      "[9, 45]: MSE Loss: 0.0164\n",
      "[9, 60]: MSE Loss: 0.0188\n",
      "Epoch 10\n",
      "[10, 15]: MSE Loss: 0.0132\n",
      "[10, 30]: MSE Loss: 0.0291\n",
      "[10, 45]: MSE Loss: 0.0281\n",
      "[10, 60]: MSE Loss: 0.0168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ntnuerc/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([3, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.07305\n",
      "########################################\n",
      "Epoch 11\n",
      "[11, 15]: MSE Loss: 0.0188\n",
      "[11, 30]: MSE Loss: 0.0231\n",
      "[11, 45]: MSE Loss: 0.0230\n",
      "[11, 60]: MSE Loss: 0.0254\n",
      "Epoch 12\n",
      "[12, 15]: MSE Loss: 0.0290\n",
      "[12, 30]: MSE Loss: 0.0323\n",
      "[12, 45]: MSE Loss: 0.0261\n",
      "[12, 60]: MSE Loss: 0.0275\n",
      "Epoch 13\n",
      "[13, 15]: MSE Loss: 0.0206\n",
      "[13, 30]: MSE Loss: 0.0177\n",
      "[13, 45]: MSE Loss: 0.0186\n",
      "[13, 60]: MSE Loss: 0.0216\n",
      "Epoch 14\n",
      "[14, 15]: MSE Loss: 0.0148\n",
      "[14, 30]: MSE Loss: 0.0147\n",
      "[14, 45]: MSE Loss: 0.0258\n",
      "[14, 60]: MSE Loss: 0.0155\n",
      "Epoch 15\n",
      "[15, 15]: MSE Loss: 0.0103\n",
      "[15, 30]: MSE Loss: 0.0111\n",
      "[15, 45]: MSE Loss: 0.0177\n",
      "[15, 60]: MSE Loss: 0.0179\n",
      "Epoch 16\n",
      "[16, 15]: MSE Loss: 0.0114\n",
      "[16, 30]: MSE Loss: 0.0114\n",
      "[16, 45]: MSE Loss: 0.0191\n",
      "[16, 60]: MSE Loss: 0.0159\n",
      "Epoch 17\n",
      "[17, 15]: MSE Loss: 0.0160\n",
      "[17, 30]: MSE Loss: 0.0191\n",
      "[17, 45]: MSE Loss: 0.0105\n",
      "[17, 60]: MSE Loss: 0.0081\n",
      "Epoch 18\n",
      "[18, 15]: MSE Loss: 0.0167\n",
      "[18, 30]: MSE Loss: 0.0103\n",
      "[18, 45]: MSE Loss: 0.0170\n",
      "[18, 60]: MSE Loss: 0.0103\n",
      "Epoch 19\n",
      "[19, 15]: MSE Loss: 0.0129\n",
      "[19, 30]: MSE Loss: 0.0074\n",
      "[19, 45]: MSE Loss: 0.0153\n",
      "[19, 60]: MSE Loss: 0.0161\n",
      "Epoch 20\n",
      "[20, 15]: MSE Loss: 0.0083\n",
      "[20, 30]: MSE Loss: 0.0097\n",
      "[20, 45]: MSE Loss: 0.0094\n",
      "[20, 60]: MSE Loss: 0.0133\n",
      "Test Loss: 0.06250\n",
      "########################################\n",
      "Epoch 21\n",
      "[21, 15]: MSE Loss: 0.0094\n",
      "[21, 30]: MSE Loss: 0.0098\n",
      "[21, 45]: MSE Loss: 0.0127\n",
      "[21, 60]: MSE Loss: 0.0098\n",
      "Epoch 22\n",
      "[22, 15]: MSE Loss: 0.0109\n",
      "[22, 30]: MSE Loss: 0.0120\n",
      "[22, 45]: MSE Loss: 0.0140\n",
      "[22, 60]: MSE Loss: 0.0071\n",
      "Epoch 23\n",
      "[23, 15]: MSE Loss: 0.0131\n",
      "[23, 30]: MSE Loss: 0.0102\n",
      "[23, 45]: MSE Loss: 0.0076\n",
      "[23, 60]: MSE Loss: 0.0080\n",
      "Epoch 24\n",
      "[24, 15]: MSE Loss: 0.0058\n",
      "[24, 30]: MSE Loss: 0.0087\n",
      "[24, 45]: MSE Loss: 0.0087\n",
      "[24, 60]: MSE Loss: 0.0143\n",
      "Epoch 25\n",
      "[25, 15]: MSE Loss: 0.0069\n",
      "[25, 30]: MSE Loss: 0.0083\n",
      "[25, 45]: MSE Loss: 0.0127\n",
      "[25, 60]: MSE Loss: 0.0107\n",
      "Epoch 26\n",
      "[26, 15]: MSE Loss: 0.0068\n",
      "[26, 30]: MSE Loss: 0.0069\n",
      "[26, 45]: MSE Loss: 0.0085\n",
      "[26, 60]: MSE Loss: 0.0069\n",
      "Epoch 27\n",
      "[27, 15]: MSE Loss: 0.0103\n",
      "[27, 30]: MSE Loss: 0.0100\n",
      "[27, 45]: MSE Loss: 0.0057\n",
      "[27, 60]: MSE Loss: 0.0083\n",
      "Epoch 28\n",
      "[28, 15]: MSE Loss: 0.0069\n",
      "[28, 30]: MSE Loss: 0.0082\n",
      "[28, 45]: MSE Loss: 0.0104\n",
      "[28, 60]: MSE Loss: 0.0053\n",
      "Epoch 29\n",
      "[29, 15]: MSE Loss: 0.0074\n",
      "[29, 30]: MSE Loss: 0.0079\n",
      "[29, 45]: MSE Loss: 0.0092\n",
      "[29, 60]: MSE Loss: 0.0080\n",
      "Epoch 30\n",
      "[30, 15]: MSE Loss: 0.0056\n",
      "[30, 30]: MSE Loss: 0.0172\n",
      "[30, 45]: MSE Loss: 0.0094\n",
      "[30, 60]: MSE Loss: 0.0064\n",
      "Test Loss: 0.08224\n",
      "########################################\n",
      "Epoch 31\n",
      "[31, 15]: MSE Loss: 0.0151\n",
      "[31, 30]: MSE Loss: 0.0101\n",
      "[31, 45]: MSE Loss: 0.0058\n",
      "[31, 60]: MSE Loss: 0.0099\n",
      "Epoch 32\n",
      "[32, 15]: MSE Loss: 0.0078\n",
      "[32, 30]: MSE Loss: 0.0079\n",
      "[32, 45]: MSE Loss: 0.0082\n",
      "[32, 60]: MSE Loss: 0.0085\n",
      "Epoch 33\n",
      "[33, 15]: MSE Loss: 0.0086\n",
      "[33, 30]: MSE Loss: 0.0048\n",
      "[33, 45]: MSE Loss: 0.0100\n",
      "[33, 60]: MSE Loss: 0.0077\n",
      "Epoch 34\n",
      "[34, 15]: MSE Loss: 0.0054\n",
      "[34, 30]: MSE Loss: 0.0116\n",
      "[34, 45]: MSE Loss: 0.0103\n",
      "[34, 60]: MSE Loss: 0.0070\n",
      "Epoch 35\n",
      "[35, 15]: MSE Loss: 0.0059\n",
      "[35, 30]: MSE Loss: 0.0073\n",
      "[35, 45]: MSE Loss: 0.0072\n",
      "[35, 60]: MSE Loss: 0.0114\n",
      "Epoch 36\n",
      "[36, 15]: MSE Loss: 0.0069\n",
      "[36, 30]: MSE Loss: 0.0106\n",
      "[36, 45]: MSE Loss: 0.0093\n",
      "[36, 60]: MSE Loss: 0.0059\n",
      "Epoch 37\n",
      "[37, 15]: MSE Loss: 0.0076\n",
      "[37, 30]: MSE Loss: 0.0053\n",
      "[37, 45]: MSE Loss: 0.0074\n",
      "[37, 60]: MSE Loss: 0.0113\n",
      "Epoch 38\n",
      "[38, 15]: MSE Loss: 0.0066\n",
      "[38, 30]: MSE Loss: 0.0094\n",
      "[38, 45]: MSE Loss: 0.0079\n",
      "[38, 60]: MSE Loss: 0.0063\n",
      "Epoch 39\n",
      "[39, 15]: MSE Loss: 0.0106\n",
      "[39, 30]: MSE Loss: 0.0074\n",
      "[39, 45]: MSE Loss: 0.0084\n",
      "[39, 60]: MSE Loss: 0.0070\n",
      "Epoch 40\n",
      "[40, 15]: MSE Loss: 0.0102\n",
      "[40, 30]: MSE Loss: 0.0084\n",
      "[40, 45]: MSE Loss: 0.0081\n",
      "[40, 60]: MSE Loss: 0.0065\n",
      "Test Loss: 0.13763\n",
      "########################################\n",
      "Epoch 41\n",
      "[41, 15]: MSE Loss: 0.0077\n",
      "[41, 30]: MSE Loss: 0.0065\n",
      "[41, 45]: MSE Loss: 0.0066\n",
      "[41, 60]: MSE Loss: 0.0067\n",
      "Epoch 42\n",
      "[42, 15]: MSE Loss: 0.0074\n",
      "[42, 30]: MSE Loss: 0.0056\n",
      "[42, 45]: MSE Loss: 0.0044\n",
      "[42, 60]: MSE Loss: 0.0072\n",
      "Epoch 43\n",
      "[43, 15]: MSE Loss: 0.0057\n",
      "[43, 30]: MSE Loss: 0.0090\n",
      "[43, 45]: MSE Loss: 0.0078\n",
      "[43, 60]: MSE Loss: 0.0053\n",
      "Epoch 44\n",
      "[44, 15]: MSE Loss: 0.0068\n",
      "[44, 30]: MSE Loss: 0.0063\n",
      "[44, 45]: MSE Loss: 0.0062\n",
      "[44, 60]: MSE Loss: 0.0065\n",
      "Epoch 45\n",
      "[45, 15]: MSE Loss: 0.0084\n",
      "[45, 30]: MSE Loss: 0.0058\n",
      "[45, 45]: MSE Loss: 0.0073\n",
      "[45, 60]: MSE Loss: 0.0049\n",
      "Epoch 46\n",
      "[46, 15]: MSE Loss: 0.0081\n",
      "[46, 30]: MSE Loss: 0.0080\n",
      "[46, 45]: MSE Loss: 0.0098\n",
      "[46, 60]: MSE Loss: 0.0068\n",
      "Epoch 47\n",
      "[47, 15]: MSE Loss: 0.0060\n",
      "[47, 30]: MSE Loss: 0.0073\n",
      "[47, 45]: MSE Loss: 0.0080\n",
      "[47, 60]: MSE Loss: 0.0072\n",
      "Epoch 48\n",
      "[48, 15]: MSE Loss: 0.0062\n",
      "[48, 30]: MSE Loss: 0.0105\n",
      "[48, 45]: MSE Loss: 0.0071\n",
      "[48, 60]: MSE Loss: 0.0057\n",
      "Epoch 49\n",
      "[49, 15]: MSE Loss: 0.0046\n",
      "[49, 30]: MSE Loss: 0.0092\n",
      "[49, 45]: MSE Loss: 0.0050\n",
      "[49, 60]: MSE Loss: 0.0064\n",
      "Epoch 50\n",
      "[50, 15]: MSE Loss: 0.0056\n",
      "[50, 30]: MSE Loss: 0.0057\n",
      "[50, 45]: MSE Loss: 0.0043\n",
      "[50, 60]: MSE Loss: 0.0063\n",
      "Test Loss: 0.06584\n",
      "########################################\n",
      "Epoch 51\n",
      "[51, 15]: MSE Loss: 0.0063\n",
      "[51, 30]: MSE Loss: 0.0077\n",
      "[51, 45]: MSE Loss: 0.0049\n",
      "[51, 60]: MSE Loss: 0.0098\n",
      "Epoch 52\n",
      "[52, 15]: MSE Loss: 0.0048\n",
      "[52, 30]: MSE Loss: 0.0044\n",
      "[52, 45]: MSE Loss: 0.0053\n",
      "[52, 60]: MSE Loss: 0.0043\n",
      "Epoch 53\n",
      "[53, 15]: MSE Loss: 0.0047\n",
      "[53, 30]: MSE Loss: 0.0048\n",
      "[53, 45]: MSE Loss: 0.0029\n",
      "[53, 60]: MSE Loss: 0.0054\n",
      "Epoch 54\n",
      "[54, 15]: MSE Loss: 0.0107\n",
      "[54, 30]: MSE Loss: 0.0113\n",
      "[54, 45]: MSE Loss: 0.0093\n",
      "[54, 60]: MSE Loss: 0.0077\n",
      "Epoch 55\n",
      "[55, 15]: MSE Loss: 0.0102\n",
      "[55, 30]: MSE Loss: 0.0046\n",
      "[55, 45]: MSE Loss: 0.0109\n",
      "[55, 60]: MSE Loss: 0.0062\n",
      "Epoch 56\n",
      "[56, 15]: MSE Loss: 0.0052\n",
      "[56, 30]: MSE Loss: 0.0062\n",
      "[56, 45]: MSE Loss: 0.0084\n",
      "[56, 60]: MSE Loss: 0.0051\n",
      "Epoch 57\n",
      "[57, 15]: MSE Loss: 0.0047\n",
      "[57, 30]: MSE Loss: 0.0042\n",
      "[57, 45]: MSE Loss: 0.0075\n",
      "[57, 60]: MSE Loss: 0.0142\n",
      "Epoch 58\n",
      "[58, 15]: MSE Loss: 0.0070\n",
      "[58, 30]: MSE Loss: 0.0069\n",
      "[58, 45]: MSE Loss: 0.0074\n",
      "[58, 60]: MSE Loss: 0.0098\n",
      "Epoch 59\n",
      "[59, 15]: MSE Loss: 0.0060\n",
      "[59, 30]: MSE Loss: 0.0080\n",
      "[59, 45]: MSE Loss: 0.0092\n",
      "[59, 60]: MSE Loss: 0.0142\n",
      "Epoch 60\n",
      "[60, 15]: MSE Loss: 0.0127\n",
      "[60, 30]: MSE Loss: 0.0057\n",
      "[60, 45]: MSE Loss: 0.0067\n",
      "[60, 60]: MSE Loss: 0.0076\n",
      "Test Loss: 0.06384\n",
      "########################################\n",
      "Epoch 61\n",
      "[61, 15]: MSE Loss: 0.0103\n",
      "[61, 30]: MSE Loss: 0.0086\n",
      "[61, 45]: MSE Loss: 0.0056\n",
      "[61, 60]: MSE Loss: 0.0048\n",
      "Epoch 62\n",
      "[62, 15]: MSE Loss: 0.0047\n",
      "[62, 30]: MSE Loss: 0.0091\n",
      "[62, 45]: MSE Loss: 0.0045\n",
      "[62, 60]: MSE Loss: 0.0067\n",
      "Epoch 63\n",
      "[63, 15]: MSE Loss: 0.0049\n",
      "[63, 30]: MSE Loss: 0.0030\n",
      "[63, 45]: MSE Loss: 0.0059\n",
      "[63, 60]: MSE Loss: 0.0076\n",
      "Epoch 64\n",
      "[64, 15]: MSE Loss: 0.0041\n",
      "[64, 30]: MSE Loss: 0.0054\n",
      "[64, 45]: MSE Loss: 0.0054\n",
      "[64, 60]: MSE Loss: 0.0119\n",
      "Epoch 65\n",
      "[65, 15]: MSE Loss: 0.0038\n",
      "[65, 30]: MSE Loss: 0.0046\n",
      "[65, 45]: MSE Loss: 0.0038\n",
      "[65, 60]: MSE Loss: 0.0068\n",
      "Epoch 66\n",
      "[66, 15]: MSE Loss: 0.0055\n",
      "[66, 30]: MSE Loss: 0.0110\n",
      "[66, 45]: MSE Loss: 0.0043\n",
      "[66, 60]: MSE Loss: 0.0043\n",
      "Epoch 67\n",
      "[67, 15]: MSE Loss: 0.0072\n",
      "[67, 30]: MSE Loss: 0.0038\n",
      "[67, 45]: MSE Loss: 0.0057\n",
      "[67, 60]: MSE Loss: 0.0048\n",
      "Epoch 68\n",
      "[68, 15]: MSE Loss: 0.0056\n",
      "[68, 30]: MSE Loss: 0.0101\n",
      "[68, 45]: MSE Loss: 0.0044\n",
      "[68, 60]: MSE Loss: 0.0053\n",
      "Epoch 69\n",
      "[69, 15]: MSE Loss: 0.0054\n",
      "[69, 30]: MSE Loss: 0.0055\n",
      "[69, 45]: MSE Loss: 0.0116\n",
      "[69, 60]: MSE Loss: 0.0049\n",
      "Epoch 70\n",
      "[70, 15]: MSE Loss: 0.0069\n",
      "[70, 30]: MSE Loss: 0.0045\n",
      "[70, 45]: MSE Loss: 0.0061\n",
      "[70, 60]: MSE Loss: 0.0077\n",
      "Test Loss: 0.15543\n",
      "########################################\n",
      "Epoch 71\n",
      "[71, 15]: MSE Loss: 0.0098\n",
      "[71, 30]: MSE Loss: 0.0050\n",
      "[71, 45]: MSE Loss: 0.0049\n",
      "[71, 60]: MSE Loss: 0.0051\n",
      "Epoch 72\n",
      "[72, 15]: MSE Loss: 0.0070\n",
      "[72, 30]: MSE Loss: 0.0071\n",
      "[72, 45]: MSE Loss: 0.0045\n",
      "[72, 60]: MSE Loss: 0.0046\n",
      "Epoch 73\n",
      "[73, 15]: MSE Loss: 0.0056\n",
      "[73, 30]: MSE Loss: 0.0050\n",
      "[73, 45]: MSE Loss: 0.0047\n",
      "[73, 60]: MSE Loss: 0.0055\n",
      "Epoch 74\n",
      "[74, 15]: MSE Loss: 0.0042\n",
      "[74, 30]: MSE Loss: 0.0055\n",
      "[74, 45]: MSE Loss: 0.0060\n",
      "[74, 60]: MSE Loss: 0.0060\n",
      "Epoch 75\n",
      "[75, 15]: MSE Loss: 0.0038\n",
      "[75, 30]: MSE Loss: 0.0043\n",
      "[75, 45]: MSE Loss: 0.0055\n",
      "[75, 60]: MSE Loss: 0.0095\n",
      "Epoch 76\n",
      "[76, 15]: MSE Loss: 0.0062\n",
      "[76, 30]: MSE Loss: 0.0036\n",
      "[76, 45]: MSE Loss: 0.0063\n",
      "[76, 60]: MSE Loss: 0.0092\n",
      "Epoch 77\n",
      "[77, 15]: MSE Loss: 0.0059\n",
      "[77, 30]: MSE Loss: 0.0045\n",
      "[77, 45]: MSE Loss: 0.0086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[77, 60]: MSE Loss: 0.0066\n",
      "Epoch 78\n",
      "[78, 15]: MSE Loss: 0.0059\n",
      "[78, 30]: MSE Loss: 0.0042\n",
      "[78, 45]: MSE Loss: 0.0034\n",
      "[78, 60]: MSE Loss: 0.0033\n",
      "Epoch 79\n",
      "[79, 15]: MSE Loss: 0.0043\n",
      "[79, 30]: MSE Loss: 0.0034\n",
      "[79, 45]: MSE Loss: 0.0093\n",
      "[79, 60]: MSE Loss: 0.0032\n",
      "Epoch 80\n",
      "[80, 15]: MSE Loss: 0.0055\n",
      "[80, 30]: MSE Loss: 0.0044\n",
      "[80, 45]: MSE Loss: 0.0039\n",
      "[80, 60]: MSE Loss: 0.0110\n",
      "Test Loss: 0.06331\n",
      "########################################\n",
      "Epoch 81\n",
      "[81, 15]: MSE Loss: 0.0114\n",
      "[81, 30]: MSE Loss: 0.0058\n",
      "[81, 45]: MSE Loss: 0.0064\n",
      "[81, 60]: MSE Loss: 0.0050\n",
      "Epoch 82\n",
      "[82, 15]: MSE Loss: 0.0043\n",
      "[82, 30]: MSE Loss: 0.0042\n",
      "[82, 45]: MSE Loss: 0.0042\n",
      "[82, 60]: MSE Loss: 0.0058\n",
      "Epoch 83\n",
      "[83, 15]: MSE Loss: 0.0053\n",
      "[83, 30]: MSE Loss: 0.0033\n",
      "[83, 45]: MSE Loss: 0.0051\n",
      "[83, 60]: MSE Loss: 0.0041\n",
      "Epoch 84\n",
      "[84, 15]: MSE Loss: 0.0053\n",
      "[84, 30]: MSE Loss: 0.0033\n",
      "[84, 45]: MSE Loss: 0.0075\n",
      "[84, 60]: MSE Loss: 0.0048\n",
      "Epoch 85\n",
      "[85, 15]: MSE Loss: 0.0037\n",
      "[85, 30]: MSE Loss: 0.0044\n",
      "[85, 45]: MSE Loss: 0.0095\n",
      "[85, 60]: MSE Loss: 0.0040\n",
      "Epoch 86\n",
      "[86, 15]: MSE Loss: 0.0033\n",
      "[86, 30]: MSE Loss: 0.0062\n",
      "[86, 45]: MSE Loss: 0.0036\n",
      "[86, 60]: MSE Loss: 0.0045\n",
      "Epoch 87\n",
      "[87, 15]: MSE Loss: 0.0051\n",
      "[87, 30]: MSE Loss: 0.0032\n",
      "[87, 45]: MSE Loss: 0.0037\n",
      "[87, 60]: MSE Loss: 0.0044\n",
      "Epoch 88\n",
      "[88, 15]: MSE Loss: 0.0035\n",
      "[88, 30]: MSE Loss: 0.0040\n",
      "[88, 45]: MSE Loss: 0.0058\n",
      "[88, 60]: MSE Loss: 0.0035\n",
      "Epoch 89\n",
      "[89, 15]: MSE Loss: 0.0046\n",
      "[89, 30]: MSE Loss: 0.0050\n",
      "[89, 45]: MSE Loss: 0.0107\n",
      "[89, 60]: MSE Loss: 0.0057\n",
      "Epoch 90\n",
      "[90, 15]: MSE Loss: 0.0051\n",
      "[90, 30]: MSE Loss: 0.0035\n",
      "[90, 45]: MSE Loss: 0.0043\n",
      "[90, 60]: MSE Loss: 0.0042\n",
      "Test Loss: 0.07004\n",
      "########################################\n",
      "Epoch 91\n",
      "[91, 15]: MSE Loss: 0.0032\n",
      "[91, 30]: MSE Loss: 0.0028\n",
      "[91, 45]: MSE Loss: 0.0049\n",
      "[91, 60]: MSE Loss: 0.0028\n",
      "Epoch 92\n",
      "[92, 15]: MSE Loss: 0.0028\n",
      "[92, 30]: MSE Loss: 0.0029\n",
      "[92, 45]: MSE Loss: 0.0053\n",
      "[92, 60]: MSE Loss: 0.0047\n",
      "Epoch 93\n",
      "[93, 15]: MSE Loss: 0.0038\n",
      "[93, 30]: MSE Loss: 0.0030\n",
      "[93, 45]: MSE Loss: 0.0044\n",
      "[93, 60]: MSE Loss: 0.0080\n",
      "Epoch 94\n",
      "[94, 15]: MSE Loss: 0.0043\n",
      "[94, 30]: MSE Loss: 0.0041\n",
      "[94, 45]: MSE Loss: 0.0040\n",
      "[94, 60]: MSE Loss: 0.0039\n",
      "Epoch 95\n",
      "[95, 15]: MSE Loss: 0.0049\n",
      "[95, 30]: MSE Loss: 0.0043\n",
      "[95, 45]: MSE Loss: 0.0045\n",
      "[95, 60]: MSE Loss: 0.0039\n",
      "Epoch 96\n",
      "[96, 15]: MSE Loss: 0.0055\n",
      "[96, 30]: MSE Loss: 0.0044\n",
      "[96, 45]: MSE Loss: 0.0050\n",
      "[96, 60]: MSE Loss: 0.0039\n",
      "Epoch 97\n",
      "[97, 15]: MSE Loss: 0.0032\n",
      "[97, 30]: MSE Loss: 0.0064\n",
      "[97, 45]: MSE Loss: 0.0060\n",
      "[97, 60]: MSE Loss: 0.0053\n",
      "Epoch 98\n",
      "[98, 15]: MSE Loss: 0.0042\n",
      "[98, 30]: MSE Loss: 0.0034\n",
      "[98, 45]: MSE Loss: 0.0042\n",
      "[98, 60]: MSE Loss: 0.0042\n",
      "Epoch 99\n",
      "[99, 15]: MSE Loss: 0.0033\n",
      "[99, 30]: MSE Loss: 0.0041\n",
      "[99, 45]: MSE Loss: 0.0053\n",
      "[99, 60]: MSE Loss: 0.0049\n",
      "Epoch 100\n",
      "[100, 15]: MSE Loss: 0.0055\n",
      "[100, 30]: MSE Loss: 0.0038\n",
      "[100, 45]: MSE Loss: 0.0040\n",
      "[100, 60]: MSE Loss: 0.0030\n",
      "Test Loss: 0.13937\n",
      "########################################\n",
      "Epoch 101\n",
      "[101, 15]: MSE Loss: 0.0031\n",
      "[101, 30]: MSE Loss: 0.0032\n",
      "[101, 45]: MSE Loss: 0.0030\n",
      "[101, 60]: MSE Loss: 0.0057\n",
      "Epoch 102\n",
      "[102, 15]: MSE Loss: 0.0038\n",
      "[102, 30]: MSE Loss: 0.0094\n",
      "[102, 45]: MSE Loss: 0.0067\n",
      "[102, 60]: MSE Loss: 0.0056\n",
      "Epoch 103\n",
      "[103, 15]: MSE Loss: 0.0063\n",
      "[103, 30]: MSE Loss: 0.0038\n",
      "[103, 45]: MSE Loss: 0.0070\n",
      "[103, 60]: MSE Loss: 0.0037\n",
      "Epoch 104\n",
      "[104, 15]: MSE Loss: 0.0046\n",
      "[104, 30]: MSE Loss: 0.0049\n",
      "[104, 45]: MSE Loss: 0.0026\n",
      "[104, 60]: MSE Loss: 0.0049\n",
      "Epoch 105\n",
      "[105, 15]: MSE Loss: 0.0034\n",
      "[105, 30]: MSE Loss: 0.0032\n",
      "[105, 45]: MSE Loss: 0.0044\n",
      "[105, 60]: MSE Loss: 0.0039\n",
      "Epoch 106\n",
      "[106, 15]: MSE Loss: 0.0041\n",
      "[106, 30]: MSE Loss: 0.0047\n",
      "[106, 45]: MSE Loss: 0.0030\n",
      "[106, 60]: MSE Loss: 0.0046\n",
      "Epoch 107\n",
      "[107, 15]: MSE Loss: 0.0024\n",
      "[107, 30]: MSE Loss: 0.0024\n",
      "[107, 45]: MSE Loss: 0.0050\n",
      "[107, 60]: MSE Loss: 0.0038\n",
      "Epoch 108\n",
      "[108, 15]: MSE Loss: 0.0038\n",
      "[108, 30]: MSE Loss: 0.0034\n",
      "[108, 45]: MSE Loss: 0.0039\n",
      "[108, 60]: MSE Loss: 0.0030\n",
      "Epoch 109\n",
      "[109, 15]: MSE Loss: 0.0030\n",
      "[109, 30]: MSE Loss: 0.0029\n",
      "[109, 45]: MSE Loss: 0.0042\n",
      "[109, 60]: MSE Loss: 0.0039\n",
      "Epoch 110\n",
      "[110, 15]: MSE Loss: 0.0042\n",
      "[110, 30]: MSE Loss: 0.0061\n",
      "[110, 45]: MSE Loss: 0.0032\n",
      "[110, 60]: MSE Loss: 0.0048\n",
      "Test Loss: 0.06513\n",
      "########################################\n",
      "Epoch 111\n",
      "[111, 15]: MSE Loss: 0.0045\n",
      "[111, 30]: MSE Loss: 0.0050\n",
      "[111, 45]: MSE Loss: 0.0029\n",
      "[111, 60]: MSE Loss: 0.0023\n",
      "Epoch 112\n",
      "[112, 15]: MSE Loss: 0.0035\n",
      "[112, 30]: MSE Loss: 0.0025\n",
      "[112, 45]: MSE Loss: 0.0042\n",
      "[112, 60]: MSE Loss: 0.0030\n",
      "Epoch 113\n",
      "[113, 15]: MSE Loss: 0.0039\n",
      "[113, 30]: MSE Loss: 0.0039\n",
      "[113, 45]: MSE Loss: 0.0048\n",
      "[113, 60]: MSE Loss: 0.0038\n",
      "Epoch 114\n",
      "[114, 15]: MSE Loss: 0.0066\n",
      "[114, 30]: MSE Loss: 0.0026\n",
      "[114, 45]: MSE Loss: 0.0036\n",
      "[114, 60]: MSE Loss: 0.0031\n",
      "Epoch 115\n",
      "[115, 15]: MSE Loss: 0.0043\n",
      "[115, 30]: MSE Loss: 0.0027\n",
      "[115, 45]: MSE Loss: 0.0075\n",
      "[115, 60]: MSE Loss: 0.0043\n",
      "Epoch 116\n",
      "[116, 15]: MSE Loss: 0.0033\n",
      "[116, 30]: MSE Loss: 0.0034\n",
      "[116, 45]: MSE Loss: 0.0047\n",
      "[116, 60]: MSE Loss: 0.0042\n",
      "Epoch 117\n",
      "[117, 15]: MSE Loss: 0.0032\n",
      "[117, 30]: MSE Loss: 0.0028\n",
      "[117, 45]: MSE Loss: 0.0046\n",
      "[117, 60]: MSE Loss: 0.0054\n",
      "Epoch 118\n",
      "[118, 15]: MSE Loss: 0.0056\n",
      "[118, 30]: MSE Loss: 0.0053\n",
      "[118, 45]: MSE Loss: 0.0035\n",
      "[118, 60]: MSE Loss: 0.0050\n",
      "Epoch 119\n",
      "[119, 15]: MSE Loss: 0.0038\n",
      "[119, 30]: MSE Loss: 0.0043\n",
      "[119, 45]: MSE Loss: 0.0039\n",
      "[119, 60]: MSE Loss: 0.0071\n",
      "Epoch 120\n",
      "[120, 15]: MSE Loss: 0.0097\n",
      "[120, 30]: MSE Loss: 0.0084\n",
      "[120, 45]: MSE Loss: 0.0100\n",
      "[120, 60]: MSE Loss: 0.0113\n",
      "Test Loss: 0.06795\n",
      "########################################\n",
      "Epoch 121\n",
      "[121, 15]: MSE Loss: 0.0112\n",
      "[121, 30]: MSE Loss: 0.0082\n",
      "[121, 45]: MSE Loss: 0.0100\n",
      "[121, 60]: MSE Loss: 0.0080\n",
      "Epoch 122\n",
      "[122, 15]: MSE Loss: 0.0105\n",
      "[122, 30]: MSE Loss: 0.0084\n",
      "[122, 45]: MSE Loss: 0.0059\n",
      "[122, 60]: MSE Loss: 0.0121\n",
      "Epoch 123\n",
      "[123, 15]: MSE Loss: 0.0065\n",
      "[123, 30]: MSE Loss: 0.0109\n",
      "[123, 45]: MSE Loss: 0.0088\n",
      "[123, 60]: MSE Loss: 0.0052\n",
      "Epoch 124\n",
      "[124, 15]: MSE Loss: 0.0038\n",
      "[124, 30]: MSE Loss: 0.0037\n",
      "[124, 45]: MSE Loss: 0.0096\n",
      "[124, 60]: MSE Loss: 0.0029\n",
      "Epoch 125\n",
      "[125, 15]: MSE Loss: 0.0036\n",
      "[125, 30]: MSE Loss: 0.0040\n",
      "[125, 45]: MSE Loss: 0.0047\n",
      "[125, 60]: MSE Loss: 0.0024\n",
      "Epoch 126\n",
      "[126, 15]: MSE Loss: 0.0036\n",
      "[126, 30]: MSE Loss: 0.0031\n",
      "[126, 45]: MSE Loss: 0.0045\n",
      "[126, 60]: MSE Loss: 0.0036\n",
      "Epoch 127\n",
      "[127, 15]: MSE Loss: 0.0021\n",
      "[127, 30]: MSE Loss: 0.0042\n",
      "[127, 45]: MSE Loss: 0.0025\n",
      "[127, 60]: MSE Loss: 0.0085\n",
      "Epoch 128\n",
      "[128, 15]: MSE Loss: 0.0031\n",
      "[128, 30]: MSE Loss: 0.0086\n",
      "[128, 45]: MSE Loss: 0.0080\n",
      "[128, 60]: MSE Loss: 0.0041\n",
      "Epoch 129\n",
      "[129, 15]: MSE Loss: 0.0045\n",
      "[129, 30]: MSE Loss: 0.0027\n",
      "[129, 45]: MSE Loss: 0.0023\n",
      "[129, 60]: MSE Loss: 0.0030\n",
      "Epoch 130\n",
      "[130, 15]: MSE Loss: 0.0032\n",
      "[130, 30]: MSE Loss: 0.0044\n",
      "[130, 45]: MSE Loss: 0.0038\n",
      "[130, 60]: MSE Loss: 0.0037\n",
      "Test Loss: 0.06871\n",
      "########################################\n",
      "Epoch 131\n",
      "[131, 15]: MSE Loss: 0.0051\n",
      "[131, 30]: MSE Loss: 0.0033\n",
      "[131, 45]: MSE Loss: 0.0024\n",
      "[131, 60]: MSE Loss: 0.0021\n",
      "Epoch 132\n",
      "[132, 15]: MSE Loss: 0.0025\n",
      "[132, 30]: MSE Loss: 0.0029\n",
      "[132, 45]: MSE Loss: 0.0080\n",
      "[132, 60]: MSE Loss: 0.0030\n",
      "Epoch 133\n",
      "[133, 15]: MSE Loss: 0.0040\n",
      "[133, 30]: MSE Loss: 0.0025\n",
      "[133, 45]: MSE Loss: 0.0042\n",
      "[133, 60]: MSE Loss: 0.0034\n",
      "Epoch 134\n",
      "[134, 15]: MSE Loss: 0.0049\n",
      "[134, 30]: MSE Loss: 0.0041\n",
      "[134, 45]: MSE Loss: 0.0024\n",
      "[134, 60]: MSE Loss: 0.0038\n",
      "Epoch 135\n",
      "[135, 15]: MSE Loss: 0.0034\n",
      "[135, 30]: MSE Loss: 0.0033\n",
      "[135, 45]: MSE Loss: 0.0042\n",
      "[135, 60]: MSE Loss: 0.0023\n",
      "Epoch 136\n",
      "[136, 15]: MSE Loss: 0.0027\n",
      "[136, 30]: MSE Loss: 0.0050\n",
      "[136, 45]: MSE Loss: 0.0026\n",
      "[136, 60]: MSE Loss: 0.0043\n",
      "Epoch 137\n",
      "[137, 15]: MSE Loss: 0.0044\n",
      "[137, 30]: MSE Loss: 0.0020\n",
      "[137, 45]: MSE Loss: 0.0033\n",
      "[137, 60]: MSE Loss: 0.0029\n",
      "Epoch 138\n",
      "[138, 15]: MSE Loss: 0.0030\n",
      "[138, 30]: MSE Loss: 0.0025\n",
      "[138, 45]: MSE Loss: 0.0034\n",
      "[138, 60]: MSE Loss: 0.0026\n",
      "Epoch 139\n",
      "[139, 15]: MSE Loss: 0.0036\n",
      "[139, 30]: MSE Loss: 0.0038\n",
      "[139, 45]: MSE Loss: 0.0053\n",
      "[139, 60]: MSE Loss: 0.0043\n",
      "Epoch 140\n",
      "[140, 15]: MSE Loss: 0.0028\n",
      "[140, 30]: MSE Loss: 0.0031\n",
      "[140, 45]: MSE Loss: 0.0026\n",
      "[140, 60]: MSE Loss: 0.0027\n",
      "Test Loss: 0.16677\n",
      "########################################\n",
      "Epoch 141\n",
      "[141, 15]: MSE Loss: 0.0019\n",
      "[141, 30]: MSE Loss: 0.0027\n",
      "[141, 45]: MSE Loss: 0.0031\n",
      "[141, 60]: MSE Loss: 0.0088\n",
      "Epoch 142\n",
      "[142, 15]: MSE Loss: 0.0025\n",
      "[142, 30]: MSE Loss: 0.0026\n",
      "[142, 45]: MSE Loss: 0.0025\n",
      "[142, 60]: MSE Loss: 0.0028\n",
      "Epoch 143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[143, 15]: MSE Loss: 0.0035\n",
      "[143, 30]: MSE Loss: 0.0033\n",
      "[143, 45]: MSE Loss: 0.0037\n",
      "[143, 60]: MSE Loss: 0.0039\n",
      "Epoch 144\n",
      "[144, 15]: MSE Loss: 0.0048\n",
      "[144, 30]: MSE Loss: 0.0124\n",
      "[144, 45]: MSE Loss: 0.0179\n",
      "[144, 60]: MSE Loss: 0.0093\n",
      "Epoch 145\n",
      "[145, 15]: MSE Loss: 0.0052\n",
      "[145, 30]: MSE Loss: 0.0071\n",
      "[145, 45]: MSE Loss: 0.0057\n",
      "[145, 60]: MSE Loss: 0.0082\n",
      "Epoch 146\n",
      "[146, 15]: MSE Loss: 0.0036\n",
      "[146, 30]: MSE Loss: 0.0053\n",
      "[146, 45]: MSE Loss: 0.0053\n",
      "[146, 60]: MSE Loss: 0.0036\n",
      "Epoch 147\n",
      "[147, 15]: MSE Loss: 0.0045\n",
      "[147, 30]: MSE Loss: 0.0031\n",
      "[147, 45]: MSE Loss: 0.0037\n",
      "[147, 60]: MSE Loss: 0.0041\n",
      "Epoch 148\n",
      "[148, 15]: MSE Loss: 0.0075\n",
      "[148, 30]: MSE Loss: 0.0076\n",
      "[148, 45]: MSE Loss: 0.0059\n",
      "[148, 60]: MSE Loss: 0.0036\n",
      "Epoch 149\n",
      "[149, 15]: MSE Loss: 0.0032\n",
      "[149, 30]: MSE Loss: 0.0029\n",
      "[149, 45]: MSE Loss: 0.0041\n",
      "[149, 60]: MSE Loss: 0.0033\n",
      "Epoch 150\n",
      "[150, 15]: MSE Loss: 0.0045\n",
      "[150, 30]: MSE Loss: 0.0032\n",
      "[150, 45]: MSE Loss: 0.0033\n",
      "[150, 60]: MSE Loss: 0.0037\n",
      "Test Loss: 0.20500\n",
      "########################################\n",
      "Epoch 151\n",
      "[151, 15]: MSE Loss: 0.0051\n",
      "[151, 30]: MSE Loss: 0.0043\n",
      "[151, 45]: MSE Loss: 0.0028\n",
      "[151, 60]: MSE Loss: 0.0040\n",
      "Epoch 152\n",
      "[152, 15]: MSE Loss: 0.0034\n",
      "[152, 30]: MSE Loss: 0.0039\n",
      "[152, 45]: MSE Loss: 0.0031\n",
      "[152, 60]: MSE Loss: 0.0033\n",
      "Epoch 153\n",
      "[153, 15]: MSE Loss: 0.0033\n",
      "[153, 30]: MSE Loss: 0.0056\n",
      "[153, 45]: MSE Loss: 0.0056\n",
      "[153, 60]: MSE Loss: 0.0053\n",
      "Epoch 154\n",
      "[154, 15]: MSE Loss: 0.0031\n",
      "[154, 30]: MSE Loss: 0.0039\n",
      "[154, 45]: MSE Loss: 0.0036\n",
      "[154, 60]: MSE Loss: 0.0031\n",
      "Epoch 155\n",
      "[155, 15]: MSE Loss: 0.0052\n",
      "[155, 30]: MSE Loss: 0.0059\n",
      "[155, 45]: MSE Loss: 0.0044\n",
      "[155, 60]: MSE Loss: 0.0035\n",
      "Epoch 156\n",
      "[156, 15]: MSE Loss: 0.0036\n",
      "[156, 30]: MSE Loss: 0.0054\n",
      "[156, 45]: MSE Loss: 0.0026\n",
      "[156, 60]: MSE Loss: 0.0030\n",
      "Epoch 157\n",
      "[157, 15]: MSE Loss: 0.0024\n",
      "[157, 30]: MSE Loss: 0.0022\n",
      "[157, 45]: MSE Loss: 0.0032\n",
      "[157, 60]: MSE Loss: 0.0034\n",
      "Epoch 158\n",
      "[158, 15]: MSE Loss: 0.0031\n",
      "[158, 30]: MSE Loss: 0.0036\n",
      "[158, 45]: MSE Loss: 0.0050\n",
      "[158, 60]: MSE Loss: 0.0032\n",
      "Epoch 159\n",
      "[159, 15]: MSE Loss: 0.0033\n",
      "[159, 30]: MSE Loss: 0.0036\n",
      "[159, 45]: MSE Loss: 0.0029\n",
      "[159, 60]: MSE Loss: 0.0028\n",
      "Epoch 160\n",
      "[160, 15]: MSE Loss: 0.0044\n",
      "[160, 30]: MSE Loss: 0.0057\n",
      "[160, 45]: MSE Loss: 0.0023\n",
      "[160, 60]: MSE Loss: 0.0057\n",
      "Test Loss: 0.15534\n",
      "########################################\n",
      "Epoch 161\n",
      "[161, 15]: MSE Loss: 0.0030\n",
      "[161, 30]: MSE Loss: 0.0028\n",
      "[161, 45]: MSE Loss: 0.0060\n",
      "[161, 60]: MSE Loss: 0.0025\n",
      "Epoch 162\n",
      "[162, 15]: MSE Loss: 0.0033\n",
      "[162, 30]: MSE Loss: 0.0022\n",
      "[162, 45]: MSE Loss: 0.0028\n",
      "[162, 60]: MSE Loss: 0.0023\n",
      "Epoch 163\n",
      "[163, 15]: MSE Loss: 0.0067\n",
      "[163, 30]: MSE Loss: 0.0034\n",
      "[163, 45]: MSE Loss: 0.0033\n",
      "[163, 60]: MSE Loss: 0.0025\n",
      "Epoch 164\n",
      "[164, 15]: MSE Loss: 0.0034\n",
      "[164, 30]: MSE Loss: 0.0040\n",
      "[164, 45]: MSE Loss: 0.0020\n",
      "[164, 60]: MSE Loss: 0.0031\n",
      "Epoch 165\n",
      "[165, 15]: MSE Loss: 0.0030\n",
      "[165, 30]: MSE Loss: 0.0031\n",
      "[165, 45]: MSE Loss: 0.0039\n",
      "[165, 60]: MSE Loss: 0.0024\n",
      "Epoch 166\n",
      "[166, 15]: MSE Loss: 0.0078\n",
      "[166, 30]: MSE Loss: 0.0028\n",
      "[166, 45]: MSE Loss: 0.0058\n",
      "[166, 60]: MSE Loss: 0.0029\n",
      "Epoch 167\n",
      "[167, 15]: MSE Loss: 0.0026\n",
      "[167, 30]: MSE Loss: 0.0029\n",
      "[167, 45]: MSE Loss: 0.0014\n",
      "[167, 60]: MSE Loss: 0.0027\n",
      "Epoch 168\n",
      "[168, 15]: MSE Loss: 0.0037\n",
      "[168, 30]: MSE Loss: 0.0108\n",
      "[168, 45]: MSE Loss: 0.0096\n",
      "[168, 60]: MSE Loss: 0.0070\n",
      "Epoch 169\n",
      "[169, 15]: MSE Loss: 0.0042\n",
      "[169, 30]: MSE Loss: 0.0056\n",
      "[169, 45]: MSE Loss: 0.0042\n",
      "[169, 60]: MSE Loss: 0.0052\n",
      "Epoch 170\n",
      "[170, 15]: MSE Loss: 0.0068\n",
      "[170, 30]: MSE Loss: 0.0080\n",
      "[170, 45]: MSE Loss: 0.0045\n",
      "[170, 60]: MSE Loss: 0.0033\n",
      "Test Loss: 0.09207\n",
      "########################################\n",
      "Epoch 171\n",
      "[171, 15]: MSE Loss: 0.0055\n",
      "[171, 30]: MSE Loss: 0.0061\n",
      "[171, 45]: MSE Loss: 0.0042\n",
      "[171, 60]: MSE Loss: 0.0036\n",
      "Epoch 172\n",
      "[172, 15]: MSE Loss: 0.0107\n",
      "[172, 30]: MSE Loss: 0.0045\n",
      "[172, 45]: MSE Loss: 0.0037\n",
      "[172, 60]: MSE Loss: 0.0034\n",
      "Epoch 173\n",
      "[173, 15]: MSE Loss: 0.0059\n",
      "[173, 30]: MSE Loss: 0.0040\n",
      "[173, 45]: MSE Loss: 0.0027\n",
      "[173, 60]: MSE Loss: 0.0027\n",
      "Epoch 174\n",
      "[174, 15]: MSE Loss: 0.0031\n",
      "[174, 30]: MSE Loss: 0.0032\n",
      "[174, 45]: MSE Loss: 0.0041\n",
      "[174, 60]: MSE Loss: 0.0017\n",
      "Epoch 175\n",
      "[175, 15]: MSE Loss: 0.0030\n",
      "[175, 30]: MSE Loss: 0.0029\n",
      "[175, 45]: MSE Loss: 0.0024\n",
      "[175, 60]: MSE Loss: 0.0022\n",
      "Epoch 176\n",
      "[176, 15]: MSE Loss: 0.0033\n",
      "[176, 30]: MSE Loss: 0.0033\n",
      "[176, 45]: MSE Loss: 0.0027\n",
      "[176, 60]: MSE Loss: 0.0030\n",
      "Epoch 177\n",
      "[177, 15]: MSE Loss: 0.0035\n",
      "[177, 30]: MSE Loss: 0.0029\n",
      "[177, 45]: MSE Loss: 0.0034\n",
      "[177, 60]: MSE Loss: 0.0024\n",
      "Epoch 178\n",
      "[178, 15]: MSE Loss: 0.0028\n",
      "[178, 30]: MSE Loss: 0.0023\n",
      "[178, 45]: MSE Loss: 0.0023\n",
      "[178, 60]: MSE Loss: 0.0015\n",
      "Epoch 179\n",
      "[179, 15]: MSE Loss: 0.0024\n",
      "[179, 30]: MSE Loss: 0.0015\n",
      "[179, 45]: MSE Loss: 0.0022\n",
      "[179, 60]: MSE Loss: 0.0029\n",
      "Epoch 180\n",
      "[180, 15]: MSE Loss: 0.0018\n",
      "[180, 30]: MSE Loss: 0.0037\n",
      "[180, 45]: MSE Loss: 0.0023\n",
      "[180, 60]: MSE Loss: 0.0031\n",
      "Test Loss: 0.06823\n",
      "########################################\n",
      "Epoch 181\n",
      "[181, 15]: MSE Loss: 0.0025\n",
      "[181, 30]: MSE Loss: 0.0026\n",
      "[181, 45]: MSE Loss: 0.0041\n",
      "[181, 60]: MSE Loss: 0.0032\n",
      "Epoch 182\n",
      "[182, 15]: MSE Loss: 0.0019\n",
      "[182, 30]: MSE Loss: 0.0020\n",
      "[182, 45]: MSE Loss: 0.0020\n",
      "[182, 60]: MSE Loss: 0.0075\n",
      "Epoch 183\n",
      "[183, 15]: MSE Loss: 0.0028\n",
      "[183, 30]: MSE Loss: 0.0038\n",
      "[183, 45]: MSE Loss: 0.0035\n",
      "[183, 60]: MSE Loss: 0.0020\n",
      "Epoch 184\n",
      "[184, 15]: MSE Loss: 0.0018\n",
      "[184, 30]: MSE Loss: 0.0028\n",
      "[184, 45]: MSE Loss: 0.0036\n",
      "[184, 60]: MSE Loss: 0.0027\n",
      "Epoch 185\n",
      "[185, 15]: MSE Loss: 0.0029\n",
      "[185, 30]: MSE Loss: 0.0024\n",
      "[185, 45]: MSE Loss: 0.0017\n",
      "[185, 60]: MSE Loss: 0.0024\n",
      "Epoch 186\n",
      "[186, 15]: MSE Loss: 0.0017\n",
      "[186, 30]: MSE Loss: 0.0019\n",
      "[186, 45]: MSE Loss: 0.0018\n",
      "[186, 60]: MSE Loss: 0.0027\n",
      "Epoch 187\n",
      "[187, 15]: MSE Loss: 0.0023\n",
      "[187, 30]: MSE Loss: 0.0026\n",
      "[187, 45]: MSE Loss: 0.0028\n",
      "[187, 60]: MSE Loss: 0.0019\n",
      "Epoch 188\n",
      "[188, 15]: MSE Loss: 0.0031\n",
      "[188, 30]: MSE Loss: 0.0034\n",
      "[188, 45]: MSE Loss: 0.0025\n",
      "[188, 60]: MSE Loss: 0.0023\n",
      "Epoch 189\n",
      "[189, 15]: MSE Loss: 0.0062\n",
      "[189, 30]: MSE Loss: 0.0024\n",
      "[189, 45]: MSE Loss: 0.0029\n",
      "[189, 60]: MSE Loss: 0.0029\n",
      "Epoch 190\n",
      "[190, 15]: MSE Loss: 0.0023\n",
      "[190, 30]: MSE Loss: 0.0042\n",
      "[190, 45]: MSE Loss: 0.0019\n",
      "[190, 60]: MSE Loss: 0.0018\n",
      "Test Loss: 0.06413\n",
      "########################################\n",
      "Epoch 191\n",
      "[191, 15]: MSE Loss: 0.0022\n",
      "[191, 30]: MSE Loss: 0.0022\n",
      "[191, 45]: MSE Loss: 0.0045\n",
      "[191, 60]: MSE Loss: 0.0021\n",
      "Epoch 192\n",
      "[192, 15]: MSE Loss: 0.0021\n",
      "[192, 30]: MSE Loss: 0.0030\n",
      "[192, 45]: MSE Loss: 0.0022\n",
      "[192, 60]: MSE Loss: 0.0019\n",
      "Epoch 193\n",
      "[193, 15]: MSE Loss: 0.0026\n",
      "[193, 30]: MSE Loss: 0.0016\n",
      "[193, 45]: MSE Loss: 0.0040\n",
      "[193, 60]: MSE Loss: 0.0023\n",
      "Epoch 194\n",
      "[194, 15]: MSE Loss: 0.0013\n",
      "[194, 30]: MSE Loss: 0.0018\n",
      "[194, 45]: MSE Loss: 0.0028\n",
      "[194, 60]: MSE Loss: 0.0019\n",
      "Epoch 195\n",
      "[195, 15]: MSE Loss: 0.0035\n",
      "[195, 30]: MSE Loss: 0.0023\n",
      "[195, 45]: MSE Loss: 0.0022\n",
      "[195, 60]: MSE Loss: 0.0017\n",
      "Epoch 196\n",
      "[196, 15]: MSE Loss: 0.0036\n",
      "[196, 30]: MSE Loss: 0.0016\n",
      "[196, 45]: MSE Loss: 0.0025\n",
      "[196, 60]: MSE Loss: 0.0017\n",
      "Epoch 197\n",
      "[197, 15]: MSE Loss: 0.0030\n",
      "[197, 30]: MSE Loss: 0.0022\n",
      "[197, 45]: MSE Loss: 0.0039\n",
      "[197, 60]: MSE Loss: 0.0020\n",
      "Epoch 198\n",
      "[198, 15]: MSE Loss: 0.0022\n",
      "[198, 30]: MSE Loss: 0.0021\n",
      "[198, 45]: MSE Loss: 0.0022\n",
      "[198, 60]: MSE Loss: 0.0018\n",
      "Epoch 199\n",
      "[199, 15]: MSE Loss: 0.0019\n",
      "[199, 30]: MSE Loss: 0.0018\n",
      "[199, 45]: MSE Loss: 0.0016\n",
      "[199, 60]: MSE Loss: 0.0023\n",
      "Epoch 200\n",
      "[200, 15]: MSE Loss: 0.0028\n",
      "[200, 30]: MSE Loss: 0.0017\n",
      "[200, 45]: MSE Loss: 0.0021\n",
      "[200, 60]: MSE Loss: 0.0048\n",
      "Test Loss: 0.18541\n",
      "########################################\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "    \n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1,\n",
    "                               out_channels=32,\n",
    "                               kernel_size=(3, 3),\n",
    "                               padding=1,\n",
    "                               stride=1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=32,\n",
    "                               out_channels=64,\n",
    "                               kernel_size=(3, 3),\n",
    "                               padding=1,\n",
    "                               stride=1)\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=64,\n",
    "                               out_channels=64,\n",
    "                               kernel_size=(3, 3),\n",
    "                               padding=1,\n",
    "                               stride=1)\n",
    "        \n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=64,\n",
    "                               out_channels=128,\n",
    "                               kernel_size=(3, 3),\n",
    "                               padding=1,\n",
    "                               stride=1)\n",
    "        \n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.linear1 = nn.Linear(7*7*128, 64)\n",
    "        self.bn5 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.linear2 = nn.Linear(64, 6)\n",
    "        self.linear3 = nn.Linear(8, 1) # 6 + 2 roi_info features\n",
    "        \n",
    "        self.pool = nn.MaxPool2d((2, 2))\n",
    "        \n",
    "    def forward(self, img, roi_info):\n",
    "        o1 = F.relu(self.conv1(img))\n",
    "        o1 = self.pool(self.bn1(o1))\n",
    "        #print(o1.shape)\n",
    "        \n",
    "        o2 = F.relu(self.conv2(o1))\n",
    "        o2 = self.pool(self.bn2(o2))\n",
    "        #print(o2.shape)\n",
    "        \n",
    "        o3 = F.relu(self.conv3(o2))\n",
    "        o3 = self.pool(self.bn3(o3))\n",
    "        #print(o3.shape)\n",
    "        \n",
    "        o4 = F.relu(self.conv4(o3))\n",
    "        o4 = self.pool(self.bn4(o4))\n",
    "        #print(o4.shape)\n",
    "\n",
    "        # Keep batch dim and flatten\n",
    "        conv_out = o4.view(-1, 7*7*128)\n",
    "        \n",
    "        l1 = F.relu(self.linear1(conv_out))\n",
    "        l1 = self.bn5(l1)\n",
    "        \n",
    "        l2 = F.relu(self.linear2(l1))\n",
    "        \n",
    "        # Concat roi_info along with the processed conv features\n",
    "        concat = torch.cat((l2, roi_info), 1)\n",
    "        #print(l1[0])\n",
    "\n",
    "        # Pay attention to the activation here\n",
    "        out = self.linear3(concat)\n",
    "        \n",
    "        return out\n",
    "\n",
    "INTERVAL = 15\n",
    "    \n",
    "model = ConvNet()\n",
    "model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00025)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(200):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    for i_batch, batch in enumerate(train_loader):\n",
    "        (x_img, x_roi_info), y_volume = batch[0], batch[1].cuda()\n",
    "        x_img = x_img.cuda()\n",
    "        x_roi_info = x_roi_info.cuda()\n",
    "        \n",
    "        assert len(x_img) == len(y_volume)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred_y_volume = model(x_img, x_roi_info)\n",
    "        \n",
    "        loss = criterion(pred_y_volume, y_volume)\n",
    "        #print(pred_y_volume.shape, y_volume.shape)\n",
    "        #print(pred_y_volume[0], y_volume[0])\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i_batch % INTERVAL == INTERVAL-1:\n",
    "            running_loss += running_loss\n",
    "            print(f\"[{epoch+1}, {i_batch+1}]: MSE Loss: {running_loss/INTERVAL:.4f}\")\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    if epoch % 10 == 9:\n",
    "        test_loss = 0.0\n",
    "        total_samples = 0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for batch in test_loader:\n",
    "                (x_img, x_roi_info), y_volume = batch[0], batch[1].cuda()\n",
    "                x_img = x_img.cuda()\n",
    "                x_roi_info = x_roi_info.cuda()\n",
    "                \n",
    "                loss = criterion(pred_y_volume, y_volume)\n",
    "                test_loss += loss.item()\n",
    "                total_samples += 1\n",
    "                \n",
    "            test_loss = test_loss / total_samples\n",
    "            \n",
    "            print(f\"Test Loss: {test_loss:.5f}\")\n",
    "            print(\"#\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModelPrediction(model, depth_frames):\n",
    "    roi = findBestFrameROI(depth_frames)\n",
    "    \n",
    "    if roi is not None:\n",
    "        h, w = roi.shape\n",
    "        h = h / IMG_HEIGHT\n",
    "        w = w / IMG_WIDTH\n",
    "        \n",
    "        # Normalize and resize roi\n",
    "        roi = np.divide(roi, MAX_VAL)\n",
    "        roi = cv2.resize(roi, NET_SIZE)\n",
    "        \n",
    "        # Convert everything to tensors\n",
    "        tensor_roi = torch.Tensor(roi).unsqueeze(0)\n",
    "        tensor_roi = tensor_roi.unsqueeze(0).cuda()\n",
    "        tensor_roi_info = torch.Tensor([h, w]).unsqueeze(0).cuda()\n",
    "\n",
    "        # Feed to model and get prediction\n",
    "        with torch.no_grad():\n",
    "            pred = model(tensor_roi, tensor_roi_info)\n",
    "            return pred.item()*4000 #* ANNOTATION_STD) + ANNOTATION_MEAN\n",
    "    else:\n",
    "        print(\"Couldnt find roi\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def generatesubmission(feature,data_list):\n",
    "    df = pd.read_csv('submissions/submissionfile.csv',index_col=0)\n",
    "    df[feature] = data_list\n",
    "    df.to_csv('./submissions/submissionfile-record.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldnt find roi\n",
      "Couldnt find roi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-9dfd42fb2c6d>:35: RuntimeWarning: invalid value encountered in true_divide\n",
      "  filter1_8u = ((filter1 / filter1.max()) * 255).astype(np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldnt find roi\n",
      "Couldnt find roi\n",
      "Couldnt find roi\n",
      "Couldnt find roi\n",
      "Couldnt find roi\n",
      "Couldnt find roi\n",
      "Couldnt find roi\n",
      "Couldnt find roi\n",
      "Couldnt find roi\n",
      "Couldnt find roi\n",
      "Couldnt find roi\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "preds = []\n",
    "for j in range(10,12):\n",
    "    for i in range(84):\n",
    "        i_str = str(i)\n",
    "        _str = '0' * (4 - len(i_str)) + i_str\n",
    "        sample_frames = natsorted(glob.glob(f'Dataset/{j}/depth/{_str}/c3/*.png'))\n",
    "\n",
    "        pred = getModelPrediction(model, sample_frames)\n",
    "        if pred is not None:\n",
    "            preds.append(pred)\n",
    "        else:\n",
    "            preds.append(-1)\n",
    "for i in range(60):\n",
    "    i_str = str(i)\n",
    "    _str = '0' * (4 - len(i_str)) + i_str\n",
    "    sample_frames = natsorted(glob.glob(f'Dataset/12/depth/{_str}/c3/*.png'))\n",
    "\n",
    "    pred = getModelPrediction(model, sample_frames)\n",
    "    if pred is not None:\n",
    "        preds.append(pred)\n",
    "    else:\n",
    "        preds.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatesubmission('Container Capacity',preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
